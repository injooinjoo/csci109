109 day2 - YouTube
https://www.youtube.com/watch?v=UIV54f6nRSA

Transcript:
(00:01) Test, test, test. Great. All right, it's loud. Good morning, data science. Welcome to lecture two in CS1090Astat 109AC 209A slash CSC ci9a. I think I got them all. All right. Uh, welcome to class 2. I'll be leading the ship today. Uh, and I apologize if I'm a little jazzed up every once in a while. You know, we just had the first weekend of football, so I have a little extra
(01:10) caffeine in my system, so I might be a little energetic. We'll see how today goes. Uh, a few announcements regarding the course. P set zero. When is it due? Homework zero, P set zero, whatever you want to call it. Tomorrow at 10 p.m. That's when our homeworks will generally be due. Tuesdays 1000 p.m.
(01:36) If you are not signed up for the course at this point, make sure you do that right away. Make sure you submit homework zero on time. That means you need to register for the course. Um, and then after that, if you want to register late, you know, there's no extensions on homework zero. So, you're just going to get the zero out of one on homework zero.
(01:55) And then the same thing happens for all the future homework. So, if your friends are looking to sign up late, tell them to sign up now, submit the pet, and they can always drop later if they have to. Okay? So, homework zero due tomorrow night. Uh, there are a few there's a little chatter about readings for the course.
(02:13) Yes, the course has optional readings and those readings will always be posted on the lecture. I see lots of stuff here. You probably don't have access to all the stuff, but under the lectures on Sway on Ed, so through Canvas, go to Ed, I have lots of courses. If you click on CS109A, you click on the little lessons tab up here. That's where you're going to see our lectures.
(02:38) Like I said, I see other things because, you know, I see dead people. Um, and then lecture three is what's coming on Wednesday. That's what Chris is going to jump into with pandas and some other stuff. There's going to be a lot of code in class on Wednesday. So, just realize, bring your computer, get ready to do some coding.
(02:56) And then today, lecture two, you click on that. The general idea will be there will be preclass readings that are always optional. This is chapter one from our textbook which is free and you can also find it through the library through Harvard library. Um and it's just all a chapter one because today we're going to step through a lot of stuff that I assume a lot of you have seen before because maybe you took AP stat 100 something like that but we'll just data science it a little bit. Okay.
(03:26) Uh there are other readings also available or will be posted available on ed but you when these notes get posted oh today's notes are also there when these lessons get posted they will also have the readings involved so pre-class reading things like this okay is that available yet Chris for Wednesday's class there so you can see the reading for Wednesday's class that way okay any really pressing needs anybody has before I jump into today's lecture that everybody needs to hear.
(04:04) Any Bills fans? Buffalo Bills fans? Our old recorder was a huge Buffalo Bills fan, so I miss her. Miss her. I want to want to have a conversation with her. But that's okay. If you're not a football fan, don't worry about don't worry about it. Josh Allen is on my fantasy team. I will never talk about my fantasy team ever again.
(04:30) Okay, lecture two today is talking about data and viz. I apologize if you're a stat student. You've probably heard the first half of this a hundred times, but that's okay. We want to make sure everybody's on the same page. So today is high level. All right, what are data? It's called data science afterwards. So we know need to know what we're dealing with.
(04:48) And then how do we play with data within the world of Python? How do we visualize? How do we summarize data? Okay. And do it effectively. Talk about some nuances that come up. All right. So, what are data? Don't forget it's the key component to the data science process. Five general steps and data come in. We're going to talk about getting and wrangling the data and exploring the data.
(05:13) So, we're mostly talking about steps two and three. We are imagining there's a question we already have at mind. Maybe you don't have a question. You can sometimes come into the data science process at step two. Oh, here's a fun data set. Let's see if we can come up with some hypothesis. Hypothesis generating through our explorations.
(05:32) Okay. Where does data come from? A datam is a single measurement, single piece of information. Datam is singular, data is plural. And it's essentially just talking about uh that is understandable both to the recorder and the reader. It's a way to transfer information. Things that are measured usually, oftentimes they are numeric, but they don't have to be.
(05:58) Okay? They can be categorical, they can be nominal, they can be words. And everything now is turned into data one way or the other. So, yeah, Facebook Meta sells all your data. Twitter X, it's a little old, sells all your data. Yelp keeps track of all your data. And then, what is this? Pablo's favorite. You don't have one of these? I thought you had one of these.
(06:24) I thought you played with one of these. Google Glass. You know, you can just walk around with those cool funky looking glasses uh and get data out of the world you're just looking at. All right. So, where do data come from? Well, you might create your own data internally or the company you work for. You're collecting data. You're doing a scientific study.
(06:42) I work in the world of medicine all the time. All the time. And in the world of medicine, we're collecting data, primary data collection. All right? Why? Because we're doing an experiment. We're doing a clinical trial, something like that. We're doing an epidemiological study. We're s surveying uh observing what's going on in the real world.
(07:01) Uh there are lots of existing data sources. A lot of those will be available to you online. whether or not you scrape them or they're just available to you like Kaggle or other sports related data sets. We'll talk about Kaggle and the use of Kaggle at times in this class. It's essentially just a data science machine learning page that houses a lot of different data sources that aggregates them for you.
(07:26) And there might be some collection effort that you need to take. And this is sort of like the web scraping of uh essentially web pages on or accessing data more legally or ethically based on uh various different ways they provide it to their users. Okay. So for data that is often generated or available to us online in some ways uh one of the most common ways to access data that is data is made accessible to us is through a company's API and the various forms of data that are available through that API will be very dependent upon who you're talking to. So, if you're interacting
(08:09) with the Google Map API, the data you will be interacting with will look really different than if you're looking at the Twitter API or you're dealing with Facebook API or you're looking at Spotify API.
(08:28) They're all very different and you have to basically read their dictionaries, read everything uh that they provide and usually they'll just use Python to access that. They'll have some interface for use of Python. A lot of them do or most of them do. Okay. You can use R for a lot of them too if that's something that interests you. There's other versions of available data online.
(08:45) There's just standard data sets uh Excel spreadsheet CSV files. There's also these RSS's which is essentially uh with a lot of times blogs and news related sites information kind of streams in data streams in and there's certain ways to access those. Uh and then we'll do some web scraping as well. also a lot of times posted online. Wikipedia as an example will have lots of their information presented in tables within the HTML code that's online and you just need to know how to extract those.
(09:15) And that's kind of part of what homework one will task you to do, right? Is dealing and extracting data from available sources through web scraping. We'll get into that in a second a little bit further. So web scraping, why do we do it? Uh well, sometimes all of those other sources of data API RSS fields don't have everything or might be really difficult and cumbersome to work with or may not even be available.
(09:43) Um how do you do it? Well, we'll see a little bit in Wednesday's lecture uh in sections the next two weeks and also talk about in homework one. Uh and the question ethically we should always ask ourselves should you do it? Should you be allowed to access freely available public data online and use it for your own use? Uh if you're just trying to do some explorations for your own use, I don't see any problems with that for most uh problems unless there's some sort of privacy concern.
(10:14) Uh you want to make sure you're not accidentally publishing private information or you might not violate some sort of terms of service. So if you're doing this to publish, you have to be a lot more careful. Okay? So watch out when you use the skills you will learn in this class and use it in real life.
(10:39) Be very careful that you're not either causing harm by releasing private information or doing something illegal. It's always important to ask those questions before you start stra uh scraping data. Okay, that's where data comes from in this class. class in the data science world. It's usually available to us online.
(10:57) Sometimes we'll talk about running experiments later on in the course and collecting our own data. But once you get some data, what kinds of data w might you actually measure? What are sort of the atomic most simple data types you would measure from online data? Numbers. Numbers. Great. Numeric data. You might collect a variable that has numeric measures. Fantastic.
(11:30) What else might you measure? Strings. Categorical nominal data. Exactly. Or there's the boolean data. You might have some zeros and ones, some yeses and nos. And so we'll typically keep our things atomic when we measure data and store them in memory. So we'll have some integers and floats, different types of numeric data.
(11:52) We'll have some booleans, some yes, nos, trus, falses, zeros, ones, and then we'll have strings, sequence of symbols. And when we convert that into the world of data analysis, generally we think of these as sort of numeric data that we can look at the distribution of, we'll have categorical data.
(12:11) Strings can be uh sort of more free for uh formed than just categorical. Okay, great. So we take all those depending on the type of data we have uh we want to look at these atomic types and put more structure to them. So sometimes we might have data types that have data and time not just simple uh types of numeric data.
(12:37) We might have lists of a sequence of values. We might save our data in terms of dictionaries. So in the world of Python, we'll often have lists and arrays and we'll deal with dictionaries at times as well. Sometimes they'll be very specific. We might put a date and time stamp to it as well. Here's an example, a dictionary.
(12:55) X is where it's usually the key and Y is the value of any type that is linked to that key. So here's an example of a student record. That's me, Kevin Rder, and here are the classes I'm involved with. All right. In this framing of a dictionary, what is my key and what is being measured on that key? All right. So, those are the three different variables being measured.
(13:37) What's the key and what's the why here? version we get Kevin back to put in last get your back put in classes we get this back so the key would be essentially the lookup so first for Kevin last for raider and the classes for these two there might be unique identifier for an individual and that is likely to be the combination of first and last though there might be other Kevin raers out in the world if you Google search Kevin Rder you might find other people I don't think they're affiliated with Harvard though I think I'm the only unique Kevin
(14:08) Raider at Harvard. And then you might have lots of different values that are related to classes as well. Okay, so sort of the index key uh for a specific person or in this case the key and value look the lookup key for a particular person for the value for that key. Okay, how is this data stored? A lot of times we're going to collect lots of data, put them all together, and we're going to often want to represent that as tabular data.
(14:40) What is tabular data? That's essentially just an Excel spreadsheet. Okay? One version of another. Why do we collect things in Excel spreadsheet? Because they're easy to sort of access and work with. And a lot of the packages we'll be dealing with are hoping that your data show up in tabular form. Okay. There's lots of other structured data types.
(15:05) there's JSONs, there's XMLs, uh we have these uh dictionaries as well which are not tabular data and then there's other semistructured data sets as well. So most of the time we're going to try to work with data that are tabular because it's going to make our lives easy, right? That's what the uh packages we're going to deal with uh mostly are expecting.
(15:27) Okay, here's a simple example of a d tabular dataf frame. It was read in as a CSV file. This is within the pandas uh package in Python. And so I read in a file which was essentially an Excel spreadsheet, commaepparated values, IMD top 1000. And then we just take a quick peek at the header of it. All right.
(15:50) What are we looking at? What are in this case the observations? And what are this case the variables? The framing of tabular data set. The columns versus the rows. The columns represent variables or observations. Variables. The rows represent observations. Okay. So every row represents a different movie which has various different measures to it and every column represents a variable a measurement across those different observations. All right.
(16:26) So we might look at all right the first uh index zero movie is the Shaw Shank Redemption. Love it. It was released in 1994. Number one, the second movie, The Godfather, released in 1972. And this is from I think about a year ago. This was the essentially user rank order of movies on IMDb. Bear with me. Great. Some of these are numeric. Some of these are boolean, some of these are strings.
(16:56) Right? It's important consideration to think about with how these variables are being measured. Each type of measurement is called a variable, sometimes called an attribute, sometimes called a feature. These are sort of the dimensions of the data set. The number of attributes is often called the dimensions.
(17:14) And then we expect each table to contain a bunch of records or observations. I typically talk about them as observations and variables because that is sort of the terminology that we use in the world of statistics. In the world of machine learning, a lot of times you talk about features, but those are really kind of the predictor variables, not all the variables in general. Okay? So, we'll just talk about variables. Think about it as a column in this spreadsheet.
(17:38) And then an observation is a row in the spreadsheet. Word of warning, the use of the word sample to represent a single observation in a data frame sometimes gets used in the machine learning world. Again, I'm coming from the world of statistics and the world of sample means a collection of observations.
(17:58) So, I tend not to use the word sample unless I mean a sample of many observations with me. Samples would mean many samples of many observations. Okay, types of data. We'll see later. It's important to distinguish. We'll have these numeric quantitative variables. Sometimes they're discrete. Sometimes they're continuous.
(18:21) For those of you who have taken stat 110, what's the big difference between discrete and continuous? Why is it important? Finite versus nonfite. Yeah, finite typically discreet or finite don't have to be. And then continuous usually are infinite in some ways. A range of values are those continuous variables. You can take on any value within that range.
(18:45) And if they're discreet, there can only be a specific set of observations it can take on, measurements it can take on. Okay? It doesn't have to necessarily be finite, though usually it is with me. So it's usually counting numbers versus continuous numbers. All right? and then compare those numeric values to those categorical variables which are usually the strings or the booleans as they're measured on your computer.
(19:15) Right? What's the big distinction? You can do a set of operations and visuals and graphs uh within when you have numeric variables, you have a specific different set of visuals, summaries and things like that if they're categorical. So always ask yourself, all right, what's being measured? Is it numeric or categorical? start there and that will make your life a lot easier throughout the uh throughout the class throughout the semester. All right, common issues.
(19:33) Well, don't forget data aren't always that simple. They're not always in perfect world set up perfectly for you. So, what do you have to do? What are some issues you might expect to see when you're dealing with data that you got from the internet or what's missing? Yeah, your data might be missing. What do you mean by missing? Yeah.
(19:59) And not all of the columns or all of the rows are measured. So for Shaw Shank Redemption, maybe we are missing uh the top actor as measured in there. Okay? Or it could be that row two is just completely blank for some reason or has blank entries. Where that missing values are, it's a question of how should we handle it? Should we try to guess what should be there? Should we try to imputee the values that are missing? Okay, if we do some analysis, what happens if you drop that row or drop that variable? What are the ramifications, repercussions of that? Okay, what other issues can happen?
(20:36) Have problems with formatting. So for example, one part of your data has like one type of the format but eventually trying to evaluate like one data set. So mismatch mismatch formatting can happen all the time. So it might be nice and clean in one data source.
(20:55) you go to another website that's supposed to be linked to it and it's not properly linked and then you're trying to make those merges happen. You have to do a lot of catching of cases of special cases. Whoops. You might have wrong values instead of missing values. You might have that messy format exactly right. So your formats might not align. And so it will be our task at times to deal with those issues.
(21:16) And homework one is really a great time to start to learn how to deal with those issues. Okay. Sometimes our data just don't match the question we're asking. So in the data science process, if we start with a question, we collect the data, we think we're in great shape, and then you get there and you find that the data aren't at a raw enough version.
(21:34) They're aggregated too much, and you can't ask the question. That's important. Or you're missing an entire subset subgroup of individuals. That is the key uh point in answering that question you posed. Okay, messy data that can happen all the time. Here's just a really quick example. All right, we want to put things in tabular form as much as possible.
(21:57) So, we're going to look at a table that's accounting for the number of produce deliveries by a company over a weekend. Think about what's being measured. What are the objects or observations? And how can we convert this table into something that's more usable for pandas for Python for our data analysis. So, what are we looking at here? We have rows and columns and we have measurements inside. Why is this not categoric? Sorry. Tabular.
(22:27) One observation per row. More than one observation per row is one way to think about it. I agree. Okay. We want a row to represent a unique observation. What would be a unique observation here? Well, in each row, there's three of them. Okay, this 15 represents one set of deliveries for a specific day, specific time of day.
(23:00) So, how can we reframe this data set to make it rectangular, to make it tabular? Instead of having the 15 here, what else do we need to measure that is combined with that 15? What should our variables be? Day and time. So we should have number of deliveries as one of our variables, day of the week as one of our variables and time of the day is one of our valuables. And so that's exactly what we could do.
(23:35) We could add an ID here as well. There are nine separate observations each with our unique ID. What's the time of day? what's the day of the week and how many deliveries were made there. Okay, both are essentially depicting the same data and information. It's just in a different format. A lot of times we could use either format, but if you were given this table for this week and then given this other table for next week, combining them into a larger data set would take a little bit of chor.
(24:05) So, it's good to have the same format. And the format we're going to be using most of the time is this tabular or rectangular data. Okay, see the distinction questions on that. Great. And that makes Pablo happy. So make sure when you deal with data as much as possible try to make them tabular. Uh why? Uh it's going to allow like I said pandas and other packages within uh Python to work a little bit more easily.
(24:36) So a lot of times that messiness might come in the column headers or values, not variable names. So when you read in data and you're having issues in Python, pandas, whatever package you're using, watch out for the first row in your data set. Does it have variable names or is it actually the first observation? That can cause issues. Variables sometimes are stored in rows and columns.
(24:58) That's kind of what we had in that uh example on the previous page. Multiple variables are stored in the same column or entry. they're not atomic in some way. So you might have a list of numbers in the entry of that rectangular data frame instead of a single atomic entry.
(25:19) Uh and you might have multiple types of experimental units stored in the same table. Essentially you're just comparing apples to oranges instead of apples to apples. Okay, in your different rows. We want that general data set, that rectangular data set to have a column to represent every single variable separately and each row to represent a separate observation.
(25:39) And that's going to make all of our uh pandas sklearn stats bobble, all those different variables uh very useful. And you'll see this will cause issues sometimes when you scrape things off the internet, off of Wikipedia or elsewhere. They don't always follow these rules and it's going to cause exceptions sometimes for you. Okay, that's what data are.
(25:56) At a very high level, very quickly, this is what we're going to be dealing with all semester long. Once you have that data, we're going to want to play around with that data. Get some patterns, find patterns and relationships within those data structures.
(26:15) First, we need to think a little bit about some statistical basics, and that's the idea of a population versus a sample. So those of you who have taken stat 111, taken stat 14, stat 100, what's the big distinction between a population and a sample, very simple. Uh a sample is a subset of you can think of population as a census as everything you could potentially measure and then a sample is a subset of that.
(26:46) Hopefully that sample is collected in a random fashion that gives us some power to do analysis then. So a population is an entire set of objects that you care about the observations you care about. It might be all students at Harvard or all students in this class and then a sample is hopefully some sort of representative sample.
(27:06) So a bad representative sample of all students in this class would be all the students that showed up today. All right. Yes, you are a sample of that larger population, but you are not a good random sample, representative sample because those students who tend to not come to class might be very different than the students who choose to come to class with me. Okay, lots of biases and samples can occur. There are all various forms of selection biases.
(27:30) Some individuals are more likely to be selected by the investigator versus a non-response or a volunteer bias. subjects or records who are not easily available or not represented. That's essentially what would be is if we collected you as a sample of all the students in CS or all the students in this class.
(27:50) It is essentially everybody who's not here doesn't have an opportunity to respond. So there will be gray area here as to whether or not that is my mistake in selecting you as the sample or those individuals who aren't here aren't able to respond. So it's a combination of those two ideas. Okay. lots of examples of these biases.
(28:09) So, and when you're working in the world of tech, a lot of times they experiment with platforms and experiment within the early adopters and they say, "Oh, look, my new app, this new version of my app in the early adopters who I randomize to seems to work much better." They buy more, they buy more uh product from us if I use this new design of the app and then they put it out into production and that doesn't show up.
(28:40) All right? Because those early adopters often are really excited to use anything that's new and fancy and then when you put it to everybody, they just get grunt disgruntled and say, "Ah, I'm not even going to bother anymore." And they walk away. So be careful of generalizing from a biased sample of early adopters or only those responders are online or only those students that come to class.
(29:04) Wow, this looks really effective, but it might not represent everybody that actually comes or the population at all. Always think about, all right, the data I'm measuring. What might it be missing? Once you collect your data, we're going to do things like calculating means. What's a sample mean? That's another word for an average or a mean. I said it. It's an average. Sorry.
(29:24) Here's one of the most complex formulas you'll see in this class. What do you do? How do you calculate an average? You add them up and divide by however many you got. Nice and simple. And don't forget sigma notation to help you out. Add up for all the indicators. X subi, observation one, x sub1, observation x sub2.
(29:48) This represents your first measurement, your second measurement up to the last measurement in that variable. Add them all up and divide by n. And here's the quick dirty summation to do that for you. Okay, great. What's a mean represent? It's the average. If you look at the distribution of measurements in a variable, it's telling you where that distribution would balance. It's the balancing point of the distribution.
(30:15) Okay? It's a measure of the center of a distribution. Over on the left, how would you describe this distribution? Normal bellshaped, symmetric at least. And that average is the balancing point. It's at that point of symmetry over on the right. This distribution, how would you describe it? Not normal, not bell-shaped, not symmetric, right? Skewed.
(30:46) Those who have taken SAT 110, what distribution kind of looks like that exponential distribution, pretty similar to an exponential distribution. And so here's the balancing point. gets pulled out to those extreme values way out in the right tail. Okay, we'll come back to this in a bit. Right? It describes what a typical sample value is. It's some measure of center of the distribution, but it has its issues.
(31:07) What's another example or another measure of the middle, the center of a distribution of measurements? The median versus the mean. What's the median? item in your set. The middle item in your set. If they're ordered, we have a numeric measure. We can put things on an ordered list.
(31:33) It's the middle number in that ordered list or the average of the two middle numbers. Okay, so the mean takes into account all the values. The median only really deals with the middle two values. Okay, so the sample median then is just essentially if you have an odd number of observation, it is the middle number.
(31:52) If you have an even number of observations in an ordered list, it's the average of the two middle numbers. So, first sort it and then look at your middle number. That's the median. You might have to average two of them. So, if we're looking at ages of students, a randomly sampled uh collection of students from this class, we have 17 to 38. I sorted it already. There are eight individuals 22 to 23. We just need to average the two. So, it's 22.5.
(32:15) The median doesn't have to be an observable value because it could be the average of two. Okay, here in this list of measurements of ages, the mean is sorry, median is 22.5. What do you guess the mean would be? There might be human calculator in here. That's fine. But roughly, what would you ballpark the mean to be in comparison to 22.5? Bigger or smaller? Bigger.
(32:41) Why? Because 38. It's got that 38 outlier in there. There's a grad student who's a little older than everybody else and it's pulling that mean up and not really having much of an effect on the median. And so the mean is probably 24 25 something like that. Okay, gives you information into the distribution in that comparison of mean to median.
(33:00) Okay, great. Median also describes what a typical observation is, but it's like the average individual rather than the average of the variable. Medians get used a lot in financial data because financial data is often right skewed. And so you talk about the median household income or the median cost rather than the mean because there's going to be some people who make a lot of money and really affect those measurements.
(33:27) Okay, great. This is just illustrating the fact that the mean is sensitive to extreme outliers. So we have the values 1 2 3 4 5. The mean and median are the same. It's symmetric, not bell-shaped but symmetric on the stop plot. We take that largest value, five, move it out to nine. The median is unaffected, but the mean goes up ever so slightly.
(33:47) Okay, every observation has bearing on the mean, not on the median. And then the classic situation is we're comparing means to medians. If we look at the histogram in this case, we'll define this again, the histogram, the distribution of a numeric variable. If we see the right tail is a little bit longer than the left tail, then we expect the mean to be a little bit bigger than the median.
(34:12) And we call that a blank skewed distribution. Right or left skew distribution. That's a rightke skewed distribution. A lot of people get this mixed up at first. A right skew distribution is uh one where the tail on the right is longer. The mean is bigger than the median. Okay, great. Bub distributions called right skewed. Think about skewess following the longer tail.
(34:38) The longer tail not where the bulk of the data are just where the longer tail is. Great. All right. Let's always think about computational time too. This isn't just a class in statistics. It's in the CS department. So we have to think about computational efficiency. When you're calculating and summarizing a data set with the mean, how many operations do you have to use? You have a list of observations. What do you have to do? Just go through the list once. Store two things.
(35:06) How many you got? What's the total? And then in the end, divide the two. So that's order n. Okay. So that's order n. Nice and quick. What about finding the median in a list of data? What do you have to do? It depends on if it's sorted or not. If it's not sorted, most of the times it won't be. If it's not sorted, what do you need to do? You got to sort.
(35:31) How fast are sorting algorithms? Typically, they are n log n if they are if you're lucky, it is just order n if things are essentially sorted already. Okay. And so what's faster? On average, the average is faster to calculate than the median. And so why a lot of times if you only pick one and you don't know if your data are going to be skewed or not, this is one reason why necessarily the mean gets reported. It's quicker to calculate when you have really big data sets.
(36:05) This could be an important consideration. All right. When you're dealing with billions of measurements over time that Facebook or Twitter or anybody else uses, thinking about speed is important. Okay. Categorical variables, mean or medians, don't make sense. Why not? How do you order them? The only reason these measures make sense is if things are ordered.
(36:35) So, we're measuring what your favorite pet is. Five people said cat. 10 people or 11 people said dog. 10 people said rat. That's my daughter. And about five people said porcupine. I don't know who has a pet porcupine. Good luck with that. Okay. How would you describe this distribution? Do not say bell-shaped. Do not say roughly symmetric.
(37:00) Why not? There's no order to the x-axis here. You could flip the rat and the porcupine and you're still having the same distribution. You don't destroy the order of the measurements, right? And so if you don't have an order of measurements on the x-axis, categorical data, pure categorical data, don't you can't really describe shape in that way.
(37:25) With skewess, with symmetry, you can't calculate means and medians. And so generally to talk about what's representative, we'll talk about modes. What's most common or what set of values are most common, right? And so here the mode, oh, most people say dog. Secondly, rat. Upset of the century. Okay, CAD is down on the bottom of the list.
(37:49) Okay, so that's a nice place to say where distributions are centered, where variables, measurements are centered, mean, median, and mode. Mode mostly for categorical data. We also want to talk about how spread out our distribution is. Simplest way to do that is to talk about range. What's the range of a data set? Probably seen it before. Look at the minimum value.
(38:13) Look at the maximum value. And look at that distance. How spread out are your points. Spread of a set of observations is important. The simplest way you've probably seen before is the range, which is just a single number, the max minus the min value. This is again for numeric data.
(38:30) Usually you'll talk about the range and you'll list both numbers because it's important to know what the min and the max are. But technically the range is a single number. More commonly what gets calculated is the variance. And from the variance, a lot of times that gets turned into the standard deviation by taking the square root. Okay? And so the variance, the notation here is going to be S squared.
(38:51) It's going to measure the spread, the average squared spread around the mean. And here's your formula. Okay, S squared. Sum up all of your measurements. How far are they from their mean? Square those distances, add them up. And then, weirdly, we divide by N minus one. It's an average square deviation, but we don't divide by n. We divide by n minus one.
(39:16) Why? For those of you who have seen this before, why is it not an average? You divide by n with an average. Why are we dividing by n minus degrees? Technical language. By dividing by n minus one, we're dividing by its degrees of freedom leading to an unbiased estimator. If you took stat 111, you're in great shape. you haven't taken stat 111 or something like it.
(39:41) What's another simplistic way to think about what n minus one is used here? Don't add everything that mean that each of the individual values influence the mean or almost pull the mean closer to them. So that means you're estimating less variance. So to correct for that you divide by a smaller number to almost intuition. Yeah.
(40:06) So the measurements we're adding up here, there are n separate measurements we're adding together in the summation, right? X1 - X^2, Xar^ squ, the sample mean squared, X2 minus the sample mean squared, n separate pieces of information. Okay? But those n separate pieces of information that we're adding together, those squared deviations are not all unique and distinct and independent.
(40:28) they are dependent upon one another because all of the separate x's the observations have to average to xbar. Okay, so the n things we're adding together are actually related in some way deterministic in some way. So when you get to the n minus one deviation measurement you automatically get the nth deviation measurement for free. Okay, this calculation by first calculating Xbar eats up a degree of freedom and that's why we divide by n minus one.
(41:05) Okay, the overly simplistic way to think about it is all right, what are we measuring here? Variance. Variance is a measure of spread in a distribution. Okay. And if I gave you a single observation and I said, "All right, this observation came from a distribution, you could guess where the center of that distribution is, but you have no way of guessing how spread out the distribution it came from is.
(41:31) " You know, I give you a single measurement and say, "What's the spread in that in that sample of data?" It's undefined. And this formula agrees with that. You have to have at least two measurements before you can talk about spread in a data set, in a variable. Okay, a real simplistic way to think about it. Yes, that is degrees of freedom and yes, it leads to an unbiased estimator for the true sigma squared. We're not getting into that at this point.
(41:54) Okay, keep in mind we're squaring these deviations. So things are going to get really uh messy when we have those extreme outlier values, whether it's low or high, it's going to increase that variance. Okay? And even more drastically than the mean S squ the problem, it doesn't have the same units as XI as the individual measurements.
(42:12) So if I told you the variance of some measure is 1,08, I have no idea what that means. It might be 10,08 ft squared and I can't get a sense of that. And that's why we take the square root to convert variance to standard deviation. And because now we're cooking with hot oil, we're on the same measurements we started with.
(42:30) All right? So oftent times you'll see what's reported the mean and standard deviation, not the mean and variance of a variable of a distribution. Okay? And so that's usually what we're going to be playing with. By taking the square root, we're now back to the same units. Things will be a little bit more interpretable. And then that standard deviation is sort of like a quasi average.
(42:48) It's not really an average because a we divided by n minus one, but more importantly, we took the square root, which destroys that average property. Okay? So it's sort of like an average, but not really. So if I tell you standard deviation is 10, you can say, well that's kind of how spread out the observations are from the center of the distribution on average. Okay, it's a quasi average. All right, those are the simple measurements we'll talk about.
(43:13) We'll come back to these ideas in the future, how they relate to estimators and the population, but for now those are just quick descriptives. You know, I give you some data. I say, "All right, get a sense for what's going on with the data. and you're going to calculate means, medians, standard deviation, things of that nature.
(43:31) Okay? But more importantly, we're going to look at what those distributions look like. We're going to create some visuals, do some EDA. This is part of the exploratory data analysis step in our data science process. All right. So, basic visualizations. We already looked at a histogram. What other visualizations have we had? We looked at a bar plot.
(43:50) Those are both good visuals for describing the distribution of a variable. Okay. What does it look like? What does its distribution look like? What other visuals have you seen before? I'm sure you've seen a a bunch that gets used in explore EDA process. Scatter plot. Great. Scatter plots are used a lot.
(44:13) What's a scatter plot great for? Looking at relationships between two values. We'll come to that. What other EDA visuals do you create? Come on. Box plots. Great. Donut plots, great. We'll talk about that. Pie charts, all kinds of visuals you can come up with. When you go to New York Times, when you go to any uh databased analysis, you'll see all these visuals. Let's define how some of these are useful.
(44:40) Why are visuals important? Real quickly, this is just to motivate a little bit why you can't just calculate summary statistics. Why you shouldn't just calculate an R squared and call it a day when you do modeling. You should explore your data a little bit. The following four data uh sets were created by this guy Anscon who said I want to create four separate data sets each with 1 2 3 4 5 roughly 12 observations where the mean of X and Y these are sort of two different variables in the same data set always sum up to the same thing always average to the same thing always
(45:15) have the same standard deviation each time. All right, these are four unique data sets that all have two variables and those two variables always have the same mean, same standard deviation. It's not shown here. Also have the same correlation between X and Y. Okay. And all right, you grab any one of these data sets, you say, "Oh, wow. These data sets look very similar in nature.
(45:37) They have the same means. They have the same spreads. They have the same correlations. But these data sets are very different. You always need to visualize the data to get a sense. How do X and Y relate? A lot of times that's the primary question we care about. If we plotted these four different data sets, we get very different ideas of how X and Y relate.
(46:03) How would you describe how X and Y relate in data set one? This is a scatter plot. Four different scatter plots. Upper left somewhat linear with randomness. How would you describe in data set two how those variables relate? Parabolic curve data set three. What's going on? We got an outlier. We got an outlier in the y direction.
(46:34) How about data set four? We got an outlier. We got an outlier in the x direction. All right. Even if you just looked at the descriptive information, you have no sense of what's going on in your data until you look at the picture. They provide a lot more information just calculating summary statistics, calculating an R squared.
(46:53) First word of warning, don't just calculate R squar and call it a day. Always look at your data. Always visualize your data in some way. Okay, another example, another motivation. So, in another class, we had a homework zero that had uh a score up to 15. This was stat 100 in a summer version that I taught. And that preclass score had an average of 50.9.
(47:18) This was based on their prerex. What should you know about stat and math? I think actually was for stat 139. I apologize. Uh the average score was 50.9. As a professor, should I be worried? students don't know what they should know coming into the class. 50.9 sounds pretty bad. It's based on prerexs. All right.
(47:43) Well, that average is a terrible summary of the students abilities. We essentially had two groups of people, just the simple average. Most everybody did reasonably well. You know, this is just a pre-est essentially homework zero. Most everybody's getting 12, 13, 14, 15. and then a whole bunch of people either submitted a blank version or didn't even do the homework at all.
(48:06) Okay, so it can be very misleading if you just report a number without actually visualizing the distribution too. Okay, just one more reason, visualize your data. This is why EDA is so important. Don't just model your data without looking at the data first. Okay, lots of motivation. They're going to help us identify patterns and trends. They're going to help us build hypotheses.
(48:31) So if we have data, it might formulate questions we can ask in a more formal way and it's going to allow us to communicate modeling results. So that last bit we'll come back to later in the semester. The use of visuals really is for exploration. Look for patterns that might not show up in our models or in our summary statistics. And later on we'll talk about using visuals to really illustrate the modeling results we get.
(48:51) This is just more for explorations right now. And it's really helpful because it might help us determine what we need to do in the analysis. You look at this scatter plot that has this curve relationship versus this scatter plot that has this linear relationship. The set of models you'll use here is very different than the set of models you use there. Okay.
(49:16) Looking visualizing doing data explorations is very important in determining what your steps will be when you want to model build prediction models things of that nature. Okay, main goals of doing visualization at the EDA step. We're going to look at distribution. That's where we're looking at histograms, bar plots. We're going to talk about relationships.
(49:38) That's where the scatter plots and other things will come into play. We might talk about composition. We might want to break apart our rows, our observations into subgroups, see how things compare. And then we might also just want to do comparisons across time across different data sources. Okay, this relationship, these are sort of two subcategories in my mind of asking the relationship question. Okay, so histogram.
(50:03) What's a histogram? You're looking at three versions of it. Where did you first learn about a histogram? How old were you? My daughter's in fourth grade. She already knows what his friends. Not that because I taught her. No, she knows what a normal distribution is because I taught her. But she learned a histogram in third grade class. Okay.
(50:29) But what is a histogram? You have measurements, a numeric variable. Important. and you turn that numeric variable rather than just plotting the dots of where it exists, you start binning them into groups that are similarly measured. Okay? And so if we have a variable that's measured between -10 and positive 10, this is standard normal random observations between -10 and positive 10, you can say, all right, let's just put all the negatives and all the positives and bin them together.
(51:00) Right? It looks like we have lots of positive observations. uh and fewer negative observations or you can bin them into between the whole numbers between 0ero and one. Let's look at all the observations that fall between 0 and one. And it looks like we have roughly 180 of them. All the observations between negative 1 and zero, we have roughly 190.
(51:23) All the observations between one and two, we have roughly 200, etc., etc., etc. You look at your long list of observations, looks like we have about a thousand of them. and you define your bins, the width of those uh categories, groups of observations, and you just count how many fall within that bin, within those breaks. Bear with me.
(51:48) One piece of control we have is how many bins do we want? Do we want our bins to be wide? Do we want our bins to be median? Do we want our medium? Do we want our bins to be really, really narrow? Okay, it's an important consideration. Mattplot lib and other packages in Python will do a default, but you might want to play around a little bit as to what those bins will be.
(52:08) And the pattern you see is sensitive to the choice of those bins in a histogram. Okay, you look at this first plot. How would you describe that distribution? Looks a little left skew to me, maybe. Okay, you look at the second histogram. How would you describe that distribution? looks pretty normal bell-shaped though there is possibly maybe biodality but it's probably just an artifact in the choice of the bins.
(52:38) And then we look at the really fine tooth comb and again same idea maybe it looks like things are biodal or trrimodal or quadal multi multimodal in some way but it's an artifact of the fact that we looked at way too narrow of bins. All right. So, it might be a choice of playing around with the bins in a histogram to discern whether there are interesting patterns that exist with me.
(53:04) What's an alternative to a histogram? I start with histogram. But if I don't like my histogram, what do I do instead? Someone said it before. Boss law. Boss law can work for a distribution of data as well. Or what's a smooth version of a histogram? A kernel density estimator.
(53:39) So we might look at kernel density estimators which are essentially just smooth versions of histograms. Sort of smooths out that discreetness of the bins. Okay. So that's for a numeric variable. For a categorical variable looking at its distribution, we're going to call it a bar plot.
(53:58) What's the difference? We just have to when we aggregate count how many the frequency of what happens in each of those bars. Those bars are defined for us because they're unique categories. And so now we're back to our pets example. We don't have to worry about choice of bins. We just have to count how many people said cat, how many people said porcupine. Okay, simple enough. All right.
(54:16) And then be careful of describing this distribution. Other options to a bar plot. There's a pie chart. Seen a pie chart before. What's pie chart represent? 100%. Is the entire pie. Each slice represents a proportion of that pie. When might you prefer a pie chart to a bar plot? When might you prefer a bar plot to a pie chart? and get a sense of how much each thing is relative to the whole.
(54:49) So yeah, what you care about is relative to the whole. If naturally you want to think in percentages, maybe a pie chart will be better. But I would argue a bar plot might always be better. The problem with pie charts, it's all right, which of these groups is bigger? If you didn't have the legend or the key, which of these slices of the pie is biggest, smallest? Relatively speaking, it's hard to compare them.
(55:13) which one is biggest or smallest because the human eye has a tough time of discerning angles and slight new nuances between angles. If instead you reported all of these percentages on a bar plot, you could pretty easily depict, oh, this bar is higher than the other and so the human eye does a generally a better idea of looking at which bar is higher than another. And so bar plots I push to say generally speaking are a little bit better than pie charts on average.
(55:40) But there are other use cases. Uh in the world of finance, they love pie charts. Okay. And we love our memes. Where is this from? How I mention other my favorite bars as part as a pie chart. My favorite pie as a bar chart. H scatter plots. What's their use case? Two numeric variables and you want to see how they relate. This is coming from the world of soccer.
(56:12) We want to see how two different variables relate. We're looking at What's that? So, we're looking at uh those teams that performed better or worse than before the season started, how well they were supposed to perform. And then we looked at how consistent the squad was from one year to the next. And essentially what we see here is this relationship.
(56:38) This is sort of uh a madeup uh statistic. Uh this shows that positive linear relationship and we can add a third dimension to it. We can add in this case the teams as our points. Right? So what's the general trend you see in the scatter plot? Positive, negative, positive relationship. As x goes up, y tends to go up along with it.
(57:06) Is it a strong moderate or weak relationship? reasonably strong moderate relationship. It's not one to one, but there is a clear moderately strong trend. And is it linear or nonlinear in some way? Looks reasonably linear. Are there any extreme outliers? Chills. Or chills. So when you look at a scatter plot, you get all those different bits of information uh out of the plot as comparing the relationship between two numeric variables.
(57:42) Here we have a stacked area graph which can be useful in this case where you have a numeric variable and you have a categorical variable on the y ais. And in this case it's really specific because it's looking at time trends. And this is a wonderful plot for looking at time trends. What are we looking at here? How things how the distribution of that categorical variable changes over time? How would you interpret this plot? What are we depicting? Age groups versus the year.
(58:26) We have How many individuals? That's 3 * 10 5th. 30,000. These are in thousands of individuals. So that's like 30 million individuals over time. And we have various age groups over time who's up to about 30 million in population starting off with a little under a million at 1900. Who knows? It's not the US because the US is 300s of millions.
(59:09) This is depicting the population presumably of a city or a state in the US or some city outside the US. Could be Mexico City, could be something else, but it's depicting the age distribution over time, but it's also looking at the total distribution at the same time. So, it's a nice visual to depict the trend in a population as it ages over time. Here's that kernel density estimator.
(59:39) The problem with histograms is that if you want to compare histograms across groups, it's really difficult to depict that on a single plot. All right? Because we have lots of overlapping bars and we're looking at three different variables presumably might be three different measurements or three different subgroups on the same measurement. And we want to look at how they compare.
(1:00:01) If all I showed you were the histogram of blue, red and green, those stacked multiple histograms on top of each other is tough to depict. And instead, what we do is we look at that smooth histogram, that kernel density estimator of the histogram. That kernel density estimator, there's a lot of technical details about it, but we'll just for now say it's the smooth version of the histogram.
(1:00:25) All right? It will give us a sense of a comparison of those different groups, a comparison of those different variables. In this case, what's the take-h home measure uh take-home message here? You can clearly see which distribution is the highest, which distribution is the lowest on average. And you can talk about potentially the differences in spreads in these three different variables.
(1:00:51) Okay? and differences in shapes across the three different groups. Okay, you can get a general sense of relationship or comparison across groups. What are we looking at here? This is that box plot. What's a box plot? It's essentially taking a histogram and turning it on its side the distribution of a variable depicting it vertically instead of horizontally.
(1:01:11) But it's only pulling out very specific pieces of information. Rather than looking at the whole distribution of observations, it depicts the median in the middle. The middle 50% of the observations as the box and then what are called the whiskers go to the largest and smallest observation that are not considered outliers based on some some rule.
(1:01:38) And then every observation that is considered a potential outlier, it instead depicts as a separate circle. Okay? So you can quickly compare across groups very succinctly and very directly of how those different distributions uh compare. And so it's really an oversimplified visual, but a nice little quick comparison across groups.
(1:02:05) It's hard to put multiple histograms and compare them directly. This is an oversimplified way to do that. Okay. Again, this is looking at relationships because we're comparing multiple groups at once. All right. A violin plot. What's a violin plot for those of you who have seen it? Well, what do you do to the box plot to get a violin plot? To me, it's the same general idea, except instead of looking at the box for the middle 50% and the whiskers, only depicting those things, you're taking that histogram, plotting it on one side of the box plot, taking another
(1:02:42) histogram that's the same histogram, just mirror imaged, and putting them next to each other, but looking at the smooth kernel density estimate instead, which depicts then essentially what looks like the visuals of violins, hence the name violin plot. What we're looking at is now comparing across four different days, two different sexes.
(1:03:02) We're comparing the distribution within Thursday of how uh males and females compare. We essentially have a kernel density estimator for males that is mirror imaged around the x-axis and we have have the horizontal sorry the x the box plot is also depicted within it. And so we're looking at the kernel density estimator to compare groups.
(1:03:27) So it's just a little bit more complicated version of the box plot. You'll get a chance to play with violin plots for sure in the class on homework one. Chris violin plots. Yeah, I think so. Oh, in the section. Great. Okay. Violin plots. Box plots are great when you have a numeric and a categorical variable looking at how the numeric variable compares across the categories of a categorical variable.
(1:03:53) But keep in mind, not everything is possible. Sometimes your data is too complex to visualize. You might have too many variables just to quick say what's going on in my data. You kind of have to pair them up or look at them in uh triplets. Some variables are going to be categorical. That's going to make things a little bit more difficult.
(1:04:11) And how do you plot values like yes or no on a scatter plot? So this is Kevin Garnett from about 20 years ago. He yelled, "Anything is possible." No, not anything is possible. How can you think about visualizing three variables, how they all relate? Two numeric variables, what do you do? You look at a scatter plot as a first plot uh visualization.
(1:04:33) Three different variables, you want to see how they all interrelate. What do you do? Be creative. Yes. Or scatter plots are two dimensional. What can you do instead? Make a threedimensional scatter plot. Great. What's the problem with threedimensional scatter plot? A scatter cloud, if you will. And you need to visualize it on paper on screen. Good luck trying to figure out what's going on.
(1:05:07) If I was able to create it for you threedimensionally here, we got all the space here. Might as well use it. you would be able to walk around and get a sense of how everything relates. But putting it on a 2D space depicting three-dimensional object is really difficult to do. So we have to take a more nuanced approach.
(1:05:24) If there's three variables, you have three pairs of sets of variables and you can look at three separate scatter plots to get a sense of what's going on. Or you might try to cate uh categorize one of those numeric variables. How we visualize three or more variables depends on whether they're categorical or numeric.
(1:05:44) And the best way to visualize these things kind of depend on the setting. Okay? So if you have two numeric and one categorical variable, it's easy to do. You look at a scatter plot and you change the color or change the size based on that categorical variable. Right? If you have three numeric variables, it's a little trickier.
(1:06:05) Here's an example of a three-dimensional data set as a three-dimensional scatter plot. Can you tell what's going on? No sense. It's almost impossible to depict what's going on threedimensionally when you put it on a two-dimensional screen. A better way to do that is maybe to add another dimension through time or add another dimension with color or add another dimension with size.
(1:06:31) Okay, this is coming from gap minder which is measurements across countries across time repeatedly measured over time and there's a lot of information depicted here. What's being measured? X and Y are what we have X you can read hopefully income per person. Y is life expectancy and you would expect richer countries to have a little bit longer life expectancy.
(1:06:57) Okay, but that's not the only thing that's depicted. There's other measurements being depicted. What other variables are being being depicted in this animation? Time. What? How's time being depicted with the animation snapshots over time? So, it's really multiple scatter plots where the defining those different scatter plots is the discretized version of time. What else is being depicted? Population.
(1:07:27) How's population being depicted? size, population size affects the size of the circle. And so you can see, oh, look at China, the largest country. They kind of stitch out in population. Of course, India, I think, had overtaken China uh in population size. But you can depict a fourth variable.
(1:07:51) And then there's a fifth variable or region is also depicted with color. So, five different variables all depicted at once in a single image, a single GIF, if you will, animation, right? Those choices. Why did they pick color for region or continent? Color is great for determining categorical variables, defining categorical variables.
(1:08:18) They use size for population because that can be depicted numerically. numerical size. Doing color to depict population, you would have to discretize it in some way. With me? Great. Any major messages, patterns that come out of this visual? Well, there's a positive relationship, but that positive relationship is not linear.
(1:08:51) And so there's essentially as this is also on the log scale as uh income goes up only to a certain extent does that have any relationship with life expectancy. Okay, that's X and Y and you can see how these countries change over time. You can see how the continents change over time. You see that big increase in China. China caught up really well in both life expectancy and income.
(1:09:15) was really far behind until whatever year that is until the 80s and started to catch up. I point out China because you know it's the biggest one and has tells a pretty story. The US unfortunately the US does really well on the income scale but relatively speaking for its income has a much lower life expectancy than its peers. Lots of reasons for that.
(1:09:38) This is in a class in public health but it can illustrate all those differences pretty quickly. All right, we're kind of running out of time. Uh, there's a little bit of a historical interlude here that basically is just saying, all right, visualizations aren't new. They can help tell a story.
(1:09:56) The one of some of the original data scientists include Jon Snow. No, not that Jon Snow, but Jon Snow depicted with a really effective visual to show that what we're looking at is essentially a dot plot of chalera cases back in the mid 1800s in the city of London and saw geographically depicted that around a specific pump, the Broad Street pump, people living near that all of a sudden started getting chalera.
(1:10:27) And this was used to illustrate, oh, maybe there was a contamination at that pump, right? And so just doing a little data science in the world of epidemiology, uh, led to a good outcome. Fords Nightingale around a similar time, the original data scientist in my heart. Uh she depicted in this case a beautiful rose chart looking at the relationship of deaths during the Creian war showing uh categorizing the type of death what it was due to and time in a circular fashion. Uh and then another common one, Napoleon's march through Russia.
(1:11:04) A strength strong uh illustration of the size of the army, what happened over time as they trotted to Moscow and back. They started off with an army of several thousand individuals and by the time they came back, they only had a few hundred depicting the fatalities over time and ge geography uh shown here. And here's just an updated version.
(1:11:26) All right. Uh I'm not going to have time to go through all the details of effective vis visualizations but we will have time to talk about this in class. Keep ideas having graphical integrity meaning don't lie with your graphing choices. A lot of times you want to keep it simple.
(1:11:47) Trying to produce too much information at once uh can actually be distracting. Use the right display. Use color strategically. Don't just use the rainbow color uh wheel. And make sure you know your audience. Today's magic word, bluey. B L U E Y. Bluey. And why should I care? That's from Bluey. If you had kids my age range, you would know what Bluey is.
(1:12:27) And why should I care? Yeah, make sure you refresh. It sounds like we might have an issue. Just refresh. H. Blue with a Y at the end. Blue. Bluey. Like the TV show. Bluey. You might not know it, but Blueie. You don't know Bluey? Come on. Oh, I'll have to show you some Bluey. The color with a Y at the end. Bluey. Thanks everyone. See you on Wednesday.