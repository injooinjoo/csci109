109 day3 - YouTube
https://www.youtube.com/watch?v=XDqVNFRvdwY

Transcript:
(00:02) All right, I think we're about ready to get started, folks. It is now a little past 10:30. We're going to get started. All right, so if you have not done so already, please go to ED and under the lecture three, you'll see that there is a survey. So, here we go. lecture three. There is a survey here. Uh please go here and fill this out. Even if you already filled it out, click it again.
(00:35) Your answers are saved. There's a new question at the top if you want. But if you haven't filled out the survey, please do so now. The more data, it's going to make it the more fun. I have a way of quickly pulling that down and putting it up on the net for you guys to to work with it as well.
(00:53) So, while a few people are filling out the survey, let's talk a little bit about logistics, homework zero, people submitted that last night. And homework one has been released. So, if you go to the assignments, you should now see a homework one, I believe. If not, it will be a visible. Yes, there it is. So, it's it's available.
(01:25) One thing to note about homework 1 is that like homework zero, it comes with one of these requirements.txt files because there are additional packages that were not required by homework zero that you will need for homework 1. So, the easiest thing to do is to just replicate the steps that are outlined in homework zero.
(01:44) You take UV, you point it at this file and say create an environment for me. And that's really the the general way of doing things is you want to have a uh an environment on a project by project basis. So for this project, for this homework, here's my virtual environment. So you've got that requirements.txt. If you're using or something else, you're already a pro, you can also use that requirements.txt.
(02:04) And if you really want, you could just uh pip install or UV install the packages when it complains, hey, you're missing this and you already have your own environment, just install them in there. So that's homework one. Now I know that there's a steep learning curve in the environment setup process.
(02:27) In fact, it's more like a cliff face where you want to start working on the very first homework, homework zero, and you can't even start doing anything until you can actually open the dang Jupyter notebook. So I know that's been frustrating, and some people may still be struggling with the environment. So, we do have something we're working on as a solution for you folks, which now on Canvas, you should see this Harvard on demand link.
(02:56) And if you click this guy, it's going to redirect you to an HUT page where they actually have a Jupiter set up in the cloud where it's an environment that we specified for them. So everyone has access to the same environment and all you have to do is just say hey give me access to this for a couple of hours. Don't worry about the time limit because you won't lose any data.
(03:16) It just means that you lose the ability to actually do compute. So you can say give it to me for two hours you work a little bit. If it times out you just say give me another two hours and you go back and your data is all there. But I would like to show you how to go about doing that if the internet cooperates. [Music] And for people just coming in, please fill out the survey that you will find here if I go there directly.
(03:53) Any better? Okay, here we go. This is what that on demand page looks like. If you're really adventurous, you can get a command line here. But what you probably want is this interactive apps. You may see other courses, but what you're interested in for data science, you'll see a Jupyter Lab CS 1090A. And if you click this, and I would say if you already have a local environment you're happy with, you're already good with setting up environments on your own machine, don't use this resource because it's limited. So more people have to wait longer if everybody's using it. So
(04:30) only if you're kind of stuck, you're having issues on your local machine. This is kind of the safety net. So you get this page. The defaults are pretty good. You want the course environment. We'll just say 2 hours. For the sorts of things we're doing right now, especially, you don't need anything more than a single CPU. I click launch.
(04:50) And in a minute or so, that's going to give me a link where I can jump right into a Jupyter Lab environment. Opens in your browser just like it was an environment running on your own machine. While that's spinning around, oh, here we go. So, it says it was created successfully.
(05:12) Give it a second here and then I'll see my little Where did it go? Oh, it's starting. So be patient after already waiting. This is the UI design here. Well, that that's farting around. Let's go back here to Ed. And under the survey, you'll see that there's actually a lecture notebook on ED itself.
(05:40) And if you click here, this is also something you can do today. You can view the notebook right in ED. The notebook you see here is a little intimidating. It's mostly empty. Don't worry about that. If you click this solutions thing here, this should show you a notebook that has much more output.
(06:03) So, you can follow along in this solutions notebook that has the code already here. You could maybe keep this open in a separate tab, or you could try typing along uh with what we're doing here. If you want to get this onto your local machine, I click this little file thing here to toggle the file browser. And if I right click in there, I can do download all.
(06:27) And that'll just give me a zip. Let's go back here and look at our on demand. So I've got my little eyeball says connect to Jupiter. And the idea is that uh now that you have a Jupiter in the cloud, you can upload your homework to work on here too. So you download the homework zip file from canvas.
(06:59) Your own local environment is busted or you're having issues, you can just upload it here to this on demand and do everything there. And the same goes for today's lecture notebook. If you want to play around with on demand, you download the zip, upload the zip, and then you're good to go. But on demand does seem to be a little slow today. So, what I'm going to do is I'm going to use a local Jupiter.
(07:26) For the if you're feeling a little out of out of your depth with notebooks generally in environments, my advice would be just follow along with this this solution notebook here. But what I'm going to do now is I'm going to assume Oh, this is not as many responses as I had hoped for. Let's see. About 350 plus some extension students.
(07:49) That's a little bit better. Okay. So, what I'm going to do is What's that? Oh, Pavlo submitted as well. Thank you, Pavlo. Um, I'm gonna just run this notebook here, which is going to remove everybody's email address, and I'm going to create a cleaned up version of the of the data and a kind of raw version. And then I'm just going to bundle everything up into some nice zip files.
(08:15) And what I'm going to do here, now that I've got the zip, I'm going to go back to ED and let me try this. I'm going to say there was a data folder here which had the survey as of like 35 minutes ago. And I'm going to say let's upload this one that I just made. And I'm going to save. And so I think if you want the freshest version of that data, you would just have to go to your notebook here and then do there's a little ellipses here and reset to scaffold will say make sure the thing I'm looking at is actually the most up to date. Reset to scaffolding. But it's totally
(09:16) fine if you just I think there were like 170 observations in the original one. This one we've just got 100 more to play with. All right, so let's let's dive in. Click on that solutions tab. I'm going to be using uh one of the the files that you'll see there too, which is just called live.
(09:40) So this may look a little uh masochistic here. Actually, let me let me do this because the idea is coding some examples is helpful, but you probably don't want to watch me type stuff all day. So, I have a little strategy for dealing with that. Oops. which is to be able to autoload some code snippets. Let's look at this folk here. Yes. So, I've got some little uh magic commands here that I will be using.
(10:24) All right. So, today we're talking about pandas. And most people from the survey, I'd say 60 70% already have some experience with pandas. And so those people know I'm used to downloading spreadsheets or CSVs, putting them in a table, and then manipulating them in that way. And we will we will get there.
(10:46) But I do think it's important to think about what is pandas at a very base level. And we'll talk about kind of the inner workings a little bit. So the people who are just getting started with pandas, getting introduced to pandas, you'll have a deeper understanding that's going to help you debug and make decisions when you're coding for pandas.
(11:04) And also for the people who are pretty experienced, hopefully you'll learn something new there as well. So the the big thing with pandas is giving you access to additional data types that you don't have with just the regular standard Python library. So that's the first thing I'd like to do is look at some of those. Let me make sure the font is big enough.
(11:23) Is this good for everybody in the cheap seats up there? Okay, so we're used to lists, right? We've seen this stuff before. Let's just make sure that we've got square brackets. We're used to stuff like this. Okay, it's got it's an ordered series. But now with pandas which I will import. So I'm gonna say import pandas as pd. This is a convention.
(12:01) Don't import it as np. You'll you'll not make any friends that way. So don't don't break conventions. Um I'm going to say import pandas. And then I'm going to use a constructor. So the capital letter lets me know that this is a class that I'm referring to. And I'm gonna say, build me a series, whatever that is, out of this list that I just created.
(12:28) And the first time you run something in the kernel, it's a little slow. And there's something that we get. So looking at this, okay, here are my numbers that I put in in my list. There's some other numbers over here. There's some business going on down here. What's this all about? Well, let's let's save this in a variable. I'm going to call this S. So this is SR series.
(12:50) And a nice feature of Jupiter, uh the old version of autocomplete, so not AI autocomplete, is just hitting the tab button. And most of the time it'll let you show show you what the options are. Uh sometimes it can be a little sluggish. Okay, there we go. That's nice. So that's I hit dot, I hit tab. I don't think this works on Ed, but if you're running it on my on demand or your local machine, this is nice.
(13:16) I hit the dot, I can see what my options are. One of the things I might be interested in is well, what is what is this values business that I'm talking about up here? Okay, those are the things that were in my list that I used to create the series. And it says it's an array.
(13:35) What but what is this? And this is a good thing to get in the habit of doing, which is inspecting the type of objects because what you can do with something depends on what it is. So being clear as to what object, what type of object you're working with is really important. So I'm going to say what is this? Well, it's a numpy array. So some people are familiar with that.
(13:52) So it means when you call values on a series, the thing you get out is a numpy array. So anything you can do with numpy arrays, you can do with that thing that you get back. That's very nice. So lurking inside every panda series is a numpy array which it calls values. There are some other attributes here. We've got one called index.
(14:16) And if I look at this, okay, that looks a little strange. It's some sort of range index object. And I can see it's got a start and a stop. I'm not very smart. I'm going to say make that into a list so I understand what's going on. Okay. Well, the these are the numbers that are on the side over here.
(14:37) So, these are the indices of the elements that are in the values array. Okay, that's not very cool because you might say in numpy I can certainly index into an array using indices. Well, the the index in the series is a little different. For example, I can say well s index equals 3 2 1 and then I can look at s. Oops. Well, that's confusing.
(15:11) And in fact, the index of a series doesn't have to be an integer at all. So we could do something like this. And now I can say give me the element at index a. And there's what we got. And of course this works for the other ones. So really the index oops I'm running things. This is a common thing that will cause you a lot of headache when you're doing Jupyter notebooks. So these uh these errors are informative. Running cells out of order.
(15:41) Normally when you're executing a script, everything just runs top to bottom. You know what's happening in a notebook. You've got these cells that you can execute in arbitrary order when you're clicking around. So you can say change the state of some variable and then execute a a cell that ran before but running it again something is broken. So I'm just going to recreate my little S here.
(16:06) And in fact the be the same thing to do would be to do all of this in one cell so that every time I run it the same exact things are happening except I'm going to put the import above So I'm making my series. I'm setting its index. Oh, because C is not one of the things in the index. That would be okay.
(16:31) So the index in a series you should not think of as the numerical position in the series. Think of it as a label. So it's something you can you can put there yourself. And you can do silly things like this. So I just remove the Z. But you can they don't have to be unique either. So now I get two elements back.
(17:00) So this is saying give me the give me every element in the series that has the index label a. So important distinction from what you're used to thinking of with the indices of a numpy array. And we'll see later when we're dealing with data frames. This can get you into trouble too if you're not paying attention to what's happening as you're manipulating the data frame. So we looked at the values. We looked at the index.
(17:22) There's another attribute called name. Now, if I look at my let's get rid of all this funny business here. If I look at my name of s here, that's sad. There's nothing there. What's going on? Well, by default, it's just the empty string. So, I'm not seeing anything printed out. But I could say, let's call our series Bob. And now our series has a name.
(17:49) If I just uh get rid of this dot here and look at the series again, I see values index and now the name here. The name will become the column header in our data frame. The series object is ultimately what the data frame is composed of. So each series is one column in your data frame. This name uh attribute is the name of the column.
(18:15) Okay, that's that's clear enough. The final little piece here is this DT type thing, and we can see it right here. So, it's saying it's an integer. If I change one of these, we can see it just turned into a float. Um, one thing you might say is, well, these are integers and this one is a float, but now what I got out is they're all floats and it's saying there's only one dype.
(18:45) So remember under the hood in the series the values are just a numpy array. Numpy wants everything in the array to be the same kind of thing. And we'll talk in a second about why that's the case. But what it's going to do is it's going to kind of upcast objects into other classes to say what's the kind of most needy class here and I want to appease that one. So I'm going to turn the other ones into that sort of class.
(19:12) So here all the integers turned into floats because I can represent one as a float but I can't represent 2.2 as an integer. So I that's nice because I don't have to think about that myself. It happens for free but it can also get you into trouble because if I say a here now they're all of this mysterious type object. Okay.
(19:37) And now we can talk a little bit about what's going on under the hood in the storage of the numpy array. Why numpy wants things to be of the same type and what this means concretely for you when you're manipulating data and the sort of time and uh memory footprint this is going to impose on you. So, we had some questions for stats people yesterday, maybe some questions for CS people, and there's probably overlap, quite plenty of overlap between the two, but can somebody tell me why NumPy might want to keep say everything in the array integers or everything in the array
(20:14) floats? Anyone have an idea as to this? You can just shout it out if you're okay. So I'll impose an answer. If I know the size of the thing in the array, I know how big an integer is and you say, "Give me the fifth integer in the array," I can just do a little bit of arithmetic to know exactly where that thing is in memory because I know every element in the array is stored contiguously in memory.
(20:46) Each one is of a fixed size. So I just skip that many blocks over and I can grab it for you immediately. So that makes it very very fast to pull things out of an array. But that requires that everything in the array be of the same size. That's great if we're using numerical values in our series.
(21:12) But if it's strings or you could have weird other kind of generic objects in your array, things get more complicated. So here it's saying dtype object. That's very generic. It's saying you gave me something weird. I can't tell you how big it is. So it's not going to be of any use for me to try to put that thing literally in in the memory of the array.
(21:32) So what the array is actually doing is it's storing a memory address where that thing lives. So the array is just composed of a bunch of addresses. Each one of those is of a fix fixed length. You could think of it as like the postal code in every index and then you say give me the thing at index 3.
(21:52) What you get back is originally just the address and then it has to go and find that and go to that place in memory. But that means skipping around or doing say an operation across a chunk is no longer nice and clean because it's not a contiguous piece of memory. The data is kind of all scrambled all over the memory and the computer has to jump around to find it.
(22:12) So that's what's going on with this object type. It's just saying you gave me a bunch of weird things. I can't keep them all together. I'm just going to store addresses to each of these. And that's the dype. Now we could say um can I can I tell it explicitly I actually want these all to be of type string.
(22:37) I think it just thinks of string as an object generally. But I can say let me do the integer two or the the string two. I've got a real integer, a float, and the string two. And I say I want these actually to be integer. Will it let me do it? It's going to complain. Uh can't be losslessly cast. But I think the the floats it won't complain. No, it doesn't like any of this.
(23:02) So I guess maybe this is the benefit which is you won't do something you didn't anticipate without it telling you explicitly hey you're you're going to lose information if you turn your floats and things into integers if it was 2.0 zero. Exh would it say that's fine because I'm not losing anything. Yes, exactly. Thank you.
(23:34) So, it's smart enough smarter than I am to figure that out. Um, values index name data type. That's our series. Now, let's look let's clear this junk here. Let's look at actually constructing a data frame itself. So we saw that the series was one of the data types we get and we built it with that PD.ER constructor. We're going to do something very similar with the data frame and the data frame you can build a couple of ways. One is with a list of dictionaries.
(24:09) So I'm going to have a list. It's going to be composed of two dictionaries. And each one is going to have let's say two keys like this. Okay. And let me put this on separate lines maybe to make it a little clearer as to what's going on. I don't know if that helped or not.
(24:47) Um, how I'm building the dataf frame in this way is basically I'm building it row by row. Each dictionary the key is being interpreted as the column name and then of course the value becomes the value. But that's not the only way to do this. You can also build it from a dictionary of lists. So the other way around. So there's my data frame constructor. I said a dictionary of lists.
(25:16) So what does that mean? Well, dictionaries have keys and then they have some sort of value. The values here will be lists. Actually, let's do like this. Okay, so I'm creating the same exact data frame, but here you can think of it as creating it column by column. So each key key is saying this is going to be a column, here's your data, and here's another column. Here's your data.
(25:56) I think you may have seen code like this at the very end of the last section where you were scraping data, you're putting it in dictionaries and lists of dictionaries and manipulate manipulating it that way. But then probably what you want to do if you really want to do some fancy manipulation, you're going to want to put it in a dataf frame so you can just give your list of dictionaries that you built up to this dataf frame constructor and then you're good to go.
(26:20) And I think that's what you're going to be doing at the beginning of homework one. You scrape a bunch of data, you build these lists of dictionaries, and then you pass it to this constructor. And now you've got a data frame. Okay. Series data frame. Now, let's actually look at the data itself. Yes. A little bit more. Yeah. Okay.
(26:46) All right. The read CV CSV is something you're going to be this is probably like the second line you see in pretty much every Jupyter notebook after the import pandas is the read CSV. There are a bunch of other read methods. You can you can read from your clipboard. You can read Excel, JSON, HTML, all sorts of fun stuff, but most of the time you're going to be using a CSV.
(27:13) And let's look at what data we have. And I'm going to use the raw data at first. I'm just mashing the tab button for that autocomplete because nobody likes typing stuff. And I think if I load this by itself. Here we go. We see it's a little messy, right? We've it's got the the column names are the original questions in the survey.
(27:50) That's kind of gross, but we can already see see here are a bunch of values in here. Now, that's really messy to see the whole thing printed to the screen. Another common convention is DF for the data frame. I know people who took CS50 or other intro programming classes, one of the cardinal sins is naming a variable something generic like X, right? But it I think it's acceptable and common practice to name your data frame DF if it's the only data frame you're working with in in the notebook.
(28:19) That's totally fine. So I'm going to use this head method and just to peek at it and I can say just give me two because that's a little easier to fit on the screen. So we have other inspect methods head and tail. tail just goes from the end. I think by default these are uh in order in which they were submitted.
(28:49) I'm going to skip down to a new cell so I don't have to read from disk every time. I've got my DF defined. Let's look at these columns. So these are all the messy column names and we'll we'll talk about each data type that they might we might think that they represent. and the the column names you can overwrite and we'll actually do that in just a second.
(29:14) Um, how many rows and columns are there? There's a nice shape method. And this tells me 283 rows, 19 columns. We already answered the what are the columns that was with the df.c columns. Can we get some summary statistics of the data? Well, we can, but I don't think they're going to be very helpful right now.
(29:42) We can use describe because the problem is that most of the data from the form is just represented as a string. So, trying to do things like statistics, the mean of a bunch of strings isn't going to be very isn't going to be very helpful. Um, but we can do something a little better with info. I'm going to zoom out just for a second here so we can see what's going on.
(30:08) It's telling me how many nonnull type things there are. So, how many elements of this column are not missing and then what data type it is. And you can see that almost all of them are object. So, they're strings. I think the only one that wasn't is the pandas skill level which was like a one to five thing.
(30:32) So Panda said I can interpret that all of those values as integers. So that's fine. Zoom back in. So that's info. Oops. Which is better I think most of the time than describe especially if the columns are not numeric. More compact if I just wanted to know the dypes. I think it's like this. Is it types plural? Yes. So again, mostly object. So now let's clean this up because you don't want to you're going to be manipulating this data frame.
(31:08) You don't want to be typing all those column names. So let's let's clean this up. I am going to cheat a little bit here so you don't have to watch me type all of this. I'm going to use this load thing to say slurp in this.py file and just inject it into the cell. So here are our columns.
(31:30) Let's just talk a little bit about each one and try to think about what type of data it is. And to make it easier, I'm going to say df.c columns equals these calls that we just created. And then let's look at the head and just maybe two. And it said I didn't run this cell yet. Okay. All right. All right. So now we can see that all the columns are nice and neat.
(31:56) This is another convention of make everything lowercase. Don't put spaces in there. It'll just make your life easier when you're typing these column names. Timestamp. Pandas does have a first class time object, but for our purposes, we'll probably just get rid of this because we we're not going to do too much with that. We have the program that people belong to.
(32:21) Now we could What kind of data type is this? despite what statistics uh majors might tell you, it's not ordinal. It's just categorical. So there's no, we don't think there's an inherent ranking to the the programs that people are in. I shouldn't pick on the stats people. So that's the program Jupiter. This was have you ever used Jupiter before? So what type of variable is that? A boolean variable, right? It it admits of only two values. So we can convert that to true or false.
(32:55) Python experience these were in brackets and not all the brackets were the same length or length of time but here there is a clear ordering to them. So that would be an or a categorical but it's it's has an ordinal property. Panda skill 1 through five that's just regular numeric operating system again no inherent order just categorical dark mode again boolean now things get a little more complicated and I know if I were to zoom out and print this a larger snapshot of this data frame and and Kevin were to be to be able to see some of these columns and
(33:38) what's in there it would make his skin crawl because what we've got now are strings but they're lists with like comma separated values. So for example um these first two let's maybe at the end we've got examples for languages tails is not that is not how you do it tail too. Let's see. Yes. So here we've got some a Portuguese and English speaker here.
(34:12) So this column, how would we want to treat this? Every one of those values is probably going to be slightly different. What we probably want to do is manipulate the data frame so that we've got a column for every language and then they're just boolean values. It greatly increases the number of columns we have.
(34:32) But that way you can ask questions like who are all the people that speak English and Portuguese. You're just asking who are all the people who have yes or true in this in these two columns. So that's an issue with having strings. You're going to have to manipulate them and blow them up into multiple columns. We've got a few more time ones here. date of birth, when you wake up, when you fall asleep.
(34:59) Some more uh categorical ones, favorite season, how you get your caffeine, uh preferred type of pet, and then we've got again some string ones, which are kind of messy. It does make me sad. Nobody has a favorite movie. It means either they've never seen a movie or every movie they've seen, they didn't like it. So, I don't know.
(35:20) I I I guess no movie they've seen moved them in any It didn't stick, right? You have one. Well, I don't know where you are in the data frame. People answered after you. I guess we'll find you. Do you want me to sort by age? I'm just kidding. Okay. Yeah, let's say um date of birth. And here's a nice You'll see this is probably going to be one of maybe three commands you use a lot.
(35:51) sort values date of birth and I think I can just give it the column name. Oh, date which is just called date of birth not age takes one position but it was given two. What's that? I see what you're saying. Thank you, Kevin. And oops. Now, we probably want to do head. And let's start chaining commands together. So, I'm going to say sort by date of birth.
(36:25) And then, so there's less stuff to look at, I'm going to use these bracket notation. So, it looks like indexing into an array. But here, I'm going to start picking out column names. So, I could say, well, we probably want the date of birth. Okay, that's just one column. We can see some people didn't fill it out as a nan or not a number.
(36:51) If I want multiple columns, I'm going to have to give a list of columns to these brackets. Even if I give it a list of one column, it gives me a data frame instead of a series. That's a good thing to keep in mind. You knew that, Pavlo. And then I can say how about fave movie include that as an additional. See I think let's do the problem is I think we've got all these nans.
(37:27) So the nans people didn't fill it out got put at the bottom. Now, it's kind of messing up what we want to do because I'd like to see who are the youngest and then who are the the oldest though. Pablo, I think something is Let me Let's Let's do this. The data frame again. I'm just going to start chaining these commands together.
(37:52) Really? So these are the people who didn't have any missing values. I don't know what's going on with the the date of birth. Then it's treating it like a string. Okay. So now can I say PD to date time errors don't you put me down this road here. Is that how you spell course? Okay.
(38:39) What how about this? What I'm going to do because the data is very messy and I think if you look at this data yourself, you will never fill out a survey again the same way because you'll see many questions where it seems like there's a very clear question that's being asked and then somebody will say there'll be one answer that's like it all started long ago like what are what are you doing? So really like I I don't want to I'm not trying to call call anybody out.
(39:05) Um so dataf frame operating system We might think that there were kind of very fixed few number of those things. We saw sort values. Another thing we can do is value count. Those are probably sorting and value counts. Probably the most two common uh methods. So these are all of the unique values and how many times they occur.
(39:33) There's the ones you would expect and then there's a little more some odd ones. there's some more ver rev things. So there's always some weird stuff that's going to show up uh in the data collection. So maybe what I will do, you have access to this too, is I'm going to say again pandas read CSV and I'm going to look in that data directory and there's the raw one and then there's this clean one and I'm just going to overwrite dataf frame going ahead And so this one you can see the columns are already set. And I think most of the if I now look at
(40:22) the data types DF DT type D types still mostly object. So what we might want to do is start converting some of these things to what we were just talking about of the particular type that they are. Um for example dark mode we know that that is just a boolean. So a very common thing you'll see actually I'm just going to I will go through it line by line is making an expression from the column that is going to turn into a boolean value.
(41:06) Basically you're asking a question of a column saying is it greater than this number? Does it contain this character or substring? And when you ask a col you ask these uh logical operators on a column what you get back is a big long series of all the true and falses like it's true of this row but not of this row.
(41:27) So that's very useful because I can say well df dark dark mode. This gives me the column and it's actually already been converted to true or false. But I can say if this how about uh let's see if the movies dfave movie and I'm going to say make this a string and then does that contain bat? So there's some nans that's saying this person didn't have a favorite movie so I can't tell you either way.
(42:16) There are some falses. But one thing I can do is now sum this. And in Python and a lot of other languages too, true is treated like it was one when you do arithmetic and false like a zero. So if I sum this, it should tell me how many occurrences of bat there are. None. Pablo. I I know that there's one. Okay. Yes. So I Let me see.
(42:50) So there's one movie that has the word width in the title and I No, that wasn't you, was it Pavlo? Um, and I can say, so I counted all the trues and falses, right? This gives me trues and falses. Now I can say show me the rows where the value is true. So this is what you see all the time with pandas is indexing into the data frame using a boolean array.
(43:25) So I've got an array of trus and falses and it's I just give it to the brackets on the dataf frame. I might have to do something with these nans. We'll see. It doesn't like the nan. So, I'm going to say again chaining commands fill NA with false. We'll ignore the warning there, but I just said if there's not an if there's an NA, just treat it like it's false.
(43:50) This did you really do this, Pablo? This is really you. I thought it was going to be a joke. Anyway, now the youngest person in my class. So this indexing where I say take my data frame ask some yes or no question of a column and then I get a bunch of boolean values and then I can index into the array.
(44:24) So I could say for example we've got our data frame and let's we had panda skill right now this was one that was numeric. So I can say panda skill greater than three. Now I've got a bunch of true and falses. Now I can take those true and falses. Let's just save it as a as a variable. Call it mask. What is this mask? It's just a series, right? So that's what often happens.
(45:03) You perform some operation on a series, you get back another series. And you can see that clearly by looking. We've got indices, we've got values, we've got a name, and a DT type. And now I can just take my data frame and pass this mask to index into it. And it gives me back unfortunately all of them because I didn't do head.
(45:30) So this is showing me all the rows where the panda skill is greater than three. And you can kind of see that that is true here. I might want to do head. But what does somebody does somebody notice something strange about these first elements in what got returned? So this is these are the first 10 or so or five rows. But something is weird about what we're seeing in the data frame if those really are the first couple rows.
(46:03) And that's the index label is all wonky. Now if I say index, show me what this thing is. 2 3 4 1116. Okay. Now, if I say I'm gonna call this uh well, let's just keep it the same df mask. And I want the I want to get the thing that's at the the second row here, right? So, that's a bach a bachelor's um who's speaks English.
(46:44) So I should be able to say call this DF2 df2. Can't I just say give me the location of the very first one index zero and it says I don't I don't like that I couldn't find zero. This is another common point of confusion is the distinction between lock and eyelock. Two ways of getting rows from a dataf frame or subsets of a data frame using that index but in a different way.
(47:30) Lock the pneumonic for that is begins with L. Think of label. This is where I say the actual value I see in that index, that's how I would find it. So if my DF2 we saw that this person bachelors here I would actually find this person by saying lock three and there they are because that's the actual label.
(48:10) If I wanted to get them based on their position, I would have to use this eyelock and say, remember, we start counting at zero in Python. So the second row is index i. Here we go. Same person, but that's something that's going to be causing problems for people a lot of the time. So whenever you do something like you sort the data frame, you subset the data frame, you're scrambling things, the indices are not going to change automatically.
(48:40) They're just going to keep the same label that they had before. So you may want that. Maybe that label was meaningful. Um, but most of the time it probably is just going to get you into trouble if you leave it alone. So what you probably want to do, let's go back to dataf frame. Sort values by panda skill. Going to make it a little smaller because it otherwise keeps scrolling down too much.
(49:18) And we can see the indexes the indices are all out of whack here. So what you often want to do is say reset index. And this is kind of the magic bullet. You do any sort of subsetting sorting, you probably want to throw a reset index there at the end. And we can see now two things happened. One, the actual indices make sense for this new ordering, but the old ones have come become a column.
(49:48) You may want that because maybe that was something valuable or you may not. So the most common thing you'll just see is I think drop true. So you say reset the indices but I don't care what the original ones were just throw them away. And now you see we do not have that anymore.
(50:12) I'm actually going to go to the the part where we start asking questions of the data frame. So we might ask how many distinct programs are there? We saw one way of doing this already which was value counts and that's really messy if it's that big. What is going on? That's because I'm doing it for everything. I need to say specifically I'm talking about programs.
(50:52) Here we go. So there are a lot and you can see there this is again with messy survey data. Many of these things are probably the same just written slightly differently. So we have all these like singletons. I don't know what MUP is. Um but there's a lot of interesting stuff in here. Just a general bachelors. Maybe somebody's undeclared or something.
(51:13) Um, value counts. That's very cool. We also just have unique. Maybe I don't care exactly the counts of them. I can just get a list of all the unique ones. So now I can say, well, that's an array. I think all arrays should have a shape. So there are 60 unique programs that people have put in there.
(51:41) If you're still fuzzy with numpy arrays, you can always just use the built-in len thing on these. So, 60 unique programs. How many are in each program? Of course, that was the the df program value count. You've seen me use the square bracket with a string. Another thing you can do is just dot column name. That's one reason why we don't use spaces in the names to allow us to do that.
(52:13) But you want to be careful because if you name your column something that's a method on a data frame like or attribute like head, you're going to run into trouble. So it's faster but probably safer to just use this strategy with a string. So those are the counts and we said this. Yes, some of the other columns are probably the same thing listed in different ways.
(52:37) I think we might be able to look at an example here. For example, I might say there probably several I saw several extension school people pursuing various certificates. So this code is saying go to the dataf frame and we're going to do some replace operation and we're going to use a regular expression. I believe you saw regular expressions in the first section.
(53:02) This is a pretty simple one. We're just using this sort of dot character as a wild card saying there could be any bunch of characters. Then it's going to say certificate and then any other bunch of characters. So basically any string that says certificate in it. Replace that with this particular string. And then I'm telling it the string I'm telling you to search for is is a regular expression.
(53:27) So treat it like that. And I just updated this. Can I say what is the length of this thing? Did we actually reduce the count at all? Yeah. So we collapsed two. There were at least two certificates that got collapsed that way. I I think another common one is like people who speak Mandarin may have written that in many different ways.
(53:54) So you might want to just do like a uh some sort of regular expression replace to collapse them together. Uh but don't treat Cantonese and Mandarin the same or people will get very upset of course. Um can we visualize these counts? Okay. So let's DF programs and we had value counts program singular. The section this week is on visualization.
(54:24) So you'll get plenty of more practice using mattplot liib and seabboard. But pandas actually has some pretty simple built-in plotting stuff. I'm going to break another rule and give you uh I call this x. The reason for doing that is with this autocomplete the interpreter doesn't know like once I chain commands it doesn't know what the result of.program is.
(54:50) So it can't autocomplete the next part. If I save it as an intermediate variable, this X is something definite. So it can tell me what the operations I can perform on it are. And I believe one of them is plot. And this is another helpful Jupiter tip. Not only do I have the tab autocomplete, but once I'm inside the parenthesis of a function call, if I do shift tab, I get the doc string right here, which is great. So if I forget what the arguments are.
(55:22) So I've got a series, right? That's what the programs returned, one column. And that series has a plot method. And I'm going to say I want a kind of plot. And let's say the the kind is going to be a bar plot. It's pretty messy because there are so so many of them. So, let's actually make this a little cleaner with that sort of boolean indexing thing that we just saw before. So, we know that X is a series.
(56:03) A series has values. I can say well where are those numbers greater than one and again I get a series out and the values of that series are now boolean. So now I can index into my data frame using this. It didn't like that because I have to index into X. I want to index into the same thing. Where are they greater than one? Show me specifically those rows.
(56:47) That's these rows. Now I can do my plot again. Plot. What kind of plot? A bar plot. And that's much much nicer now. Okay, proportion. Let's see. We could do something like let's let's think of maybe aggregating things together. So, we know we've got a bunch of different programs and we've got a bunch of different say years of Python experience and I want to say what's the average Python experience across programs.
(57:38) I'm going to say df where program to reduce the number and make it a little simpler. I'll say um program value count like we saw before where that's greater than two give me those rows of actually I need to I do need to create this intermediate thing here x so which are the programs that have values greater than two so it's these These are the programs that have more than two people in them.
(58:16) If I index into it, actually do it this way. X greater than two. Okay. And now, so let's call these. I'm going to save. Notice the index here is the program itself. So I can pull that out. Index. Now if I want to say remember what these are, I say these are big programs. Now can I say something like df where df do program is in big program big progue and again not to skip steps here
(59:29) another boolean array there's this nice is in method program is again just a bunch of strings of program names. I have a list of program names here that I call big progue and I'm saying for every row is the value of program in this list that I made that's boolean. So I can now index into this thing and now these are just the people that belong to a big program.
(1:00:04) And now I want to ask oh let's let's do panda skill because that's explicitly numeric here. Average panda skill across these people. I'm going to save an intermediate thing to not chain too many commands and get complicated. So I'm going to call this DF2. And then DF2 I'm going to now aggregate. I want to group by some column and collapse the rows together.
(1:00:38) And that column will be program which doesn't have an underscore. Okay. Is this right? This looks kind of strange because I just got some weird object back. It's not showing me a table. The problem is that we told pandas, I want you to collapse a bunch of rows together, but We didn't tell it how to aggregate. So it has a but for every row that has the same program the values for those students in the other columns are very different.
(1:01:10) How do I put them together? Do I concatenate them together as a list? Do I just take the maximum value out of all those? What should I do? So we have to be explicit about how to aggregate them. So I'm going to call this a method. This is a common pattern group by and then agg. And I think this is going to complain if I try to aggregate everything because if I say mean, I don't think that's a valid operation on some of the columns.
(1:01:41) It's going to say you've got some strings. That's not fair. Why'd you ask me to do that? So often you just want to aggregate specific columns. So I might say give it a dictionary and say well there's this column called panda skill and I want you to aggregate that using the mean. If this doesn't work we'll just subset the the data frame. Okay that worked.
(1:02:10) So again I say collapse it all the rows together that share the same program. How do I combine those rows that got collapsed together using this agg. But I have to tell it specifically which rows or which columns need to be aggregated in what fashion. So take the mean of panda skill to aggregate them together.
(1:02:34) Now of course I can then do sort values here on panda skill. I believe this will work as well. No judgments here. This is just an exercise, right? Uh I mean you're learning pandas in in the class, so we didn't expect people to be pros already. But here you can actually see chain together across these two cells. Maybe the four most common operations.
(1:03:02) We did value counts. We created a boolean index to pick out something. We did a group by and aggregated and then sorted by the values. So, it's actually the it looks like the extension students have the most experience. Not surprising because they're probably older on average and many of them already work in uh software industry.
(1:03:29) So, that's group by. Um I'll just load a couple of these other cells. The idea is that for the section with visualization, you will be able to load into the notebook for the exercise there, this cleaned data uh this clean data frame and then you can create visualizations and explore your own questions as well.
(1:03:50) But I'm just going to load some answers to some of these. So what are the languages spoken by students here? It's a long one. Um, so I'm going to say first of all take the language column and then I want to do a string operation on that. Once I call this str on a column, I basically have access to all of our regular Python string methods which are you probably used a lot of in homework zero.
(1:04:17) So I'm saying that language column I want you to split on this comma space and then I want you to explode it and also do this replace thing here to kind of collapse some of the representations from Mandarin. Find how many unique ones there are and then turn it into a list. So we can see some people being a little cheeky with Python and R and SQL.
(1:04:48) Um there's I think somebody Yeah. Oh, this person is very is struggling obviously. Um but so but also pretty pretty interesting all the the number of languages that people speak here. So this is this is a data set that you now have access to and you can play around with in the section.
(1:05:11) the greatest number of languages spoken by anyone. Let's see if we can do this maybe as one of the final exercises and try to build it up from scratch. I think what I want to do so let's let's think about the kind of operations we want to perform at a high level like you're writing pseudo code because that's really what you want to do when you're manipulating data frames.
(1:05:43) You don't want to fall into the trap of just knowing here are these five methods that exist in pandas and then trying to force all of your your new ideas into those methods because chances are if there's some there's some way of doing what you want to do. So first think think it out in kind of pseudo code or just natural language and then try to find the methods that map onto those little operations that you're describing.
(1:06:07) So languages are currently a set of strings that h are commaepparated. So I'm going to start a cell below this one and we'll we'll build it up from scratch. So DF languages, this is just going to give me a series in the first two people. Okay, but I want to do I want to split it on some people have multiple languages. Let's split it on this comma thing.
(1:06:35) What does that give me? Okay, so it went to every row and just like you would expect with a regular string split operator, it turned them into lists. Now that's nice. We're getting somewhere. Now, what does this what does this explode thing do? That sounds dramatic. Okay. Wow. So, now there's Let's see. before I had explode.
(1:07:07) If I do a dot shape on this thing 283 after I have the explode 577. So what happened? I think if explode takes a label like this. We'll build it up by saying here's my split languages. Let's make a new column in the data frame. We'll just call this one lang. So, I'm just saying take this series that I got out as a uh output of this command, plug it into the data frame as a new column, and we'll call it lang.
(1:07:59) and then can I say explode lang specifically? Yes. So if we look at what actually happened, we we saw that the number of rows increased. What it did was it created duplicate rows for students who had multiple languages in their list. So that now every one of their rows just has a single value for that.
(1:08:34) So now this this new lang column that we created I'm sorry um these are all the things that were separated by columns now. So seems promising but now we've got many more rows. What we were asking was which student speaks the most languages or what's the most number of languages anyone speaks. Here's where group by is going to come in handy again because I've got a duplicate row for every student if for every language they speak.
(1:09:12) So let's group by um let's see oh I guess the the issue here is that they don't have unique identifiers. So what I can say uh if I skip this part here and say df.reset reset index. We saw that a side effect of this was that I got this yucky index column that I didn't want before.
(1:09:47) But now this may come in useful because if I say explode that thing, I believe I'll still have this index column here, but it now be duplicated for the same student. So yes, here's somebody who spoke two languages and we've got to actually it looked like it even did it for the regular label. So let's uh if I do group by on this index column, I get my goofy thing out here that we have to aggregate.
(1:10:24) I squashed all the rows together that had the same index values. So those are the unique students. And then I want to aggregate them. And again, what are we we interested in? We're interested in this lang column that we made. And we wanted to ask what's the maximum number of languages anybody speaks.
(1:10:48) So I think we can just say take those elements and just sum them all together. So, you're basically asking how many rows each student has in the data frame. Oh, no, no, no. That's not going to work. Actually, the the easiest way to do this would be just say after I've done this exploding business, I can just do um value counts on the index, right? Because each each student has multiple rows for every language they speak. They have a unique index.
(1:11:26) So for example, student with index 51 appears five times in the data frame which means that they had five rows created for them which means they must speak five languages. And it looks like that's the the value. I don't know if the value counts are sorted by default, but it appears that they are. So in the in the section, you will have this cleaned data frame with the column names all nice.
(1:11:52) You'll have examples of seabor plotting stuff and then you'll be able to kind of run wild and make plots and ask questions of this yourself. One thing you'll see in the section is that you don't have to do a lot of manipulation of the data frame to create plots. As long as you've got nice columns, the Seabor library allows you to just give it a data frame and say, I want the x-axis to be using this column.
(1:12:15) Make the color depend on this column. Make the shape of the dot depend on this column. So, uh you can create some pretty fancy plots without having to manipulate the data frame in place. But I think we're we're about out of time here. So, thank you everybody. I'll stick around if you have any questions about uh pandas.