109day8 - YouTube
https://www.youtube.com/watch?v=OcdXscocxJM

Transcript:
(00:02) All right. We're starting. I found it here. So, I wanted to play with it. So, don't let Chris play. Welcome, welcome, welcome everyone. I'm your lecturer, Pablo Protobas. Today it will be my last one before I come back for the decision trees. After today, uh Kevin will take over and he's going to do sort of what we have done but a little bit more formal more in the probabilistic model.
(00:45) So I skipped some stuff for today because he's going to cover them in the next few lectures. Okay. So today is going to finish this and then we're going to be talking about precision. How we sure how are we sure we're doing the right thing? Okay. So, let's start with this very quickly. Okay. And then we any questions before remember this week is a quiz question.
(01:10) We did send some uh practice questions on Friday. I'm going to put later today another set of practice questions. Just practice, right? Don't get the thing. And then uh this week is the quiz question is 30 minutes to repeat. You can take one uh sheet of paper, legal paper, not the long one. You can type it, you can write it, you can whatever you want.
(01:36) Uh actually either type it or write it. Just don't leave room for changes. And it's going to be add your sections. Uh the for our extension school students, Chris sent a post. Please look at it. There's sometimes you can do it. Uh besides that, that's all I have. All right, let's start.
(01:59) So last time we finished the technicalities of the reach and the lasso regression. The idea is quite simple. We kind of realize that when we overfeit our coefficients of our predictors have become extreme values. And he said okay if that's the manifestation overfeeding why don't we just shrink those? So we added an extra extra penalty in our loss function. If we add the sum of the squares of that the L2 norm we call it reach.
(02:26) If it was just the abs the sum of the absolute values which is the L1 norm which we call lasso. Two different ways. After that I went on to dis explain or describe how we find this hyper parameter the regularization coefficient the regularization parameter lambda. Sometimes you're going to see it as theta but it doesn't matter.
(02:52) is the regularization parameter and to do that we explained how you do it with simple one validation set and then of course you can extend that to cross validation it is a little bit confusing I do understand it I mean once you understand it and you digest it is not confusing at all but through the years I found that the students uh need to implement it once to see it just go through it by yourself it's not so complicated we fix the lambda we fit the parameter ters and then we test how good is that lambda with those parameters on a validation set. Just to remember when we choose the model we're not evaluating in the full
(03:31) loss with the regularization term just MSE because that's what we car all right so that's kind of where we left and few of you were asking already where shall I use lasso when should I lose reach uh there is not one answer and I kind of introduce the idea that data science is partly science partly art you need to get a little bit of intuition You of course need to know what are the limitations of each one of them and depending on your data and depending on your problem you may choose one or the other in reality what I do I try both of
(04:07) them and that's anyway and then I see which one gives me the best validation uh MSE or perform okay all right so let's go a little bit more systematic uh the first one is that the rich regression has a closed form solution solution for the beta coefficients. That means once I have the data, the only thing I do is just plug it into this equation, the normal equation. The only difference now, if you remember, this is XRpose X.
(04:38) Now I have this extra term which is plus lambda and the I there is the identity matrix, the matrix that has one diagonally zero everywhere. and then I invert that and then I multiply by the transpose and then multiply by Y. Notice X and Y are data.
(05:03) So that means if I have the data then I create my design matrix my data matrix X the rest is just pl format. Is that fast? Yes. Why is it not? It's absolutely right. There is a little bit limitation here that you're inverting a matrix and when you're inverting a matrix could be complicated if you have a lot of data but in general when we train we don't have millions of data we have thousands and if Kevin was here you would say 100 is enough few hundred is enough but is inverting a matrix of I don't know thousand by thousand on your computer these days is extremely fast okay so boom so the advantage of the reach is that it can be
(05:49) done with a closed form solution. Now, lasso or lasso uh does not have a closed form solution. So, we need to use some kind of a trick. Uh we call them solvers. Anything that has kind of numerical thing is called a solver. Uh in the case of lasso, you may think numerical techniques like u gradient descent. We don't have to do gradient descent.
(06:13) There's actually tricks which I'm not going to get into this class, but I mentioned last time there is tricks you can do it. Nevertheless, the important thing is that there's no close solution and therefore the subgradient sub differentiation will be slower. Okay. Now, we're going to see pretty much this is the last time you see a closed form solution.
(06:37) From now on, nothing is going to have closed form solution. And we're going to have which one? Special cases. have those. Okay. You can do logistic regression with close from solution. I'm going to be looking forward to that. Um let's have a bet. Okay. So, uh in general besides what special cases that Kevin says which I'm not aware, uh there are not many closed form solutions.
(07:17) you have to do some solvers, right? Um, okay. So, the first thing we want to point out is that reach is faster. So, if speed is a concern, you're going to have to go with reach. Lastly, it will be slower. Uh, the second one, let's look at how actually my coefficients change as I increase lambda. I did mention that if lambda is very large the term of the loss function that depends on the how well you predict in the MSE part will become insignificant meaning if you have two terms in an equation you minimize and one becomes much larger the other one kind of doesn't exist you
(07:55) don't pay attention to it okay so when lambda becomes extremely large the MSE doesn't matter now to minimize that term term of the regularization the regularization term there is a very easy way to minimize it put everything to zero okay there's no need to worry about so if you look at the very large lambdas the the coefficients become zero and for both cases so if I make lambda bigger and bigger these converge to zero and that makes sense right the sum of the squares of some things will be zero if All these numbers are zero. Yeah. And
(08:38) since a square the smallest number I can get is zero. So if I can get to zero it's guaranteed that's your minimum. And since I'm adding absolute values the sum of absolute values to can't be negative. So if zero if I can get zero that's guaranteed to be the smallest. Okay. So that's the first thing I want to see.
(08:55) If I increase lambda then all the coefficients become zero. So what you see here in different colors are the values of the coefficients as we increase lambda as we increase the regularization par. Now if I go to lambda is equal to zero I'm going back to MSE and if you look this value and these values will be exactly the same as lambda is equal to zero because we're minimizing the MSE. Okay.
(09:22) So those are the two extremes. Now let's see how it goes from one side to the other. Now you can see here on the reach that the coefficients are shrunk as we expected. As we increase lambda they get smaller. That was our original goal right make them small. So you can see them getting smaller. And the same with lasso the balls get smaller.
(09:46) There's a difference though in the characteristics and I did mention it quickly last uh week that in the lasso case. So if I have let's say five coefficients and I want the sum of the absolute values to be z or the sum of the absolute or the square to be zero there is two ways to do make everything small or choose some of them to be zero. It so happens and there is many explanations to that that for lasso it prefers to set some of the coefficients zero and the others getting smaller where in the reach it makes all of them smaller and you can see it here as we increase lambda this coefficient the orange one
(10:24) became zero the others are linearly going down but that one becomes zero in the rich case you can see they can go faster down but they all going down in the same way where in the case of the lasso some of them will become zero. Okay. So now let's think about what does it mean to have some coefficients to be zero.
(10:47) The coefficient of the parameter is zero means what? No correlation means that predictor does not affect the response. Right? In other words, we can throw it away. Right? So if it doesn't affect the response, why will I put into my model? So lasso does model selection. It selects the predictors that we need. Okay. So that's a good uh thing to have.
(11:15) So as I said, the reach is faster. Lasso has the advantage of doing model selection, predictor selection. Right? Now, if you wonder why this happens, as I said, there's many explanation. There is one explanation that is graphical and I'll go through it and I hope you get some idea. If not we can just send you many many different ways to see that. Let me explain this to see if it makes sense.
(11:42) So I am minimizing the sum of two terms. Okay. So the first term is the MSE which I have here. Now what I see is in the space of two parameters beta 1 and beta 2. And remember the MSE is quadratic with respect to the parameters. It's y minus beta something square. So it's quadratic in the parameter. So you will have this nice shape like that. What do I show here? These lines here they call the contours.
(12:13) They are lines that they represent same value of the MSE. Same value of what I'm trying to mean. That's a contour. So that means along this line the MSE would remain the same and I'm going so the red contours there represent the MSE the first term this one represents the contours of the second term in case of ridge is beta squares so they are circles so the minimum will happen when both of them intersect when you have two minimizations the minimum will happen there.
(12:48) So if you think about in any random scenario when these two intersect could be anywhere on this circle. Okay. Now in the case of lasso the second term is the sum of the absolute values. And if you look at the contour of that it's just a straight lines going down. And then because you take the absolute a straight line of this straight line of this and straight line of this. So it has this trapezoidal or rhombus shape.
(13:16) Now if you let's say randomly you select two things here the chance of them intersecting are going to be on the epics what is it called the point the point the point there is a name for that right uh on the point there so the other way I like to think is like you have this ro and then you have a balloon and it flies around the chance of touching that will be on the very pointy things Right now let's see what happens there.
(13:48) At this point beta 0 has some value and beta 1 has zero. Okay. So beta 1 here is zero and beta 2 here on the other corner is zero etc. So that means that with the lasso the chance of getting some of the coefficients zero are much higher. So that's why you see this very nice uh shape as we saw before. Okay. So let's compare the two.
(14:22) The pros of the lasso is feature selection. Automatically performs feature selection by setting some coefficients to zero. Simplicity. The results is simpler models that easier to interpret and the cons is computational complexity is much more expensive to calculate. Now these slides and this line of thought is 30 years old.
(14:49) Uh right now with modern computers yes it it is more expensive but not makes a difference instead of 0.1 seconds is 2 seconds but who cares right? So that's what I said at the end of the day what I do I try both of them. Okay I wouldn't say oh this is too expensive I won't be trying it. There's scenarios that you have to do this a lot of times your data latch and it's going to hit you but in general it's not going to be you're not going to be waiting there for long.
(15:21) Uh it's not like you're running some neuron network minimization that takes forever. Uh now let's look at the other side. The pro stability stabilizing coefficients make it useful for link conditional multipolinearity data and the computation complexity it is much lower. Okay. to the cons it doesn't do future selection feature selection all right so these are the two things TLDDR too long did not read try both of them okay it's good though to have an understanding that lasso would do feature selection and it's good to understand that reach is faster okay those are the two takeout home
(16:01) um all right since we have a quiz coming up I'm going going to do one game just to warm up and then we go into bootstrapping. Okay. So, who wants to play for one free attendance? Anybody who is behind in their attendance is your chance. And let's get some data scientists. You want it, right? Yes. Okay. Okay. Your name is Lee.
(16:37) Uh, my name is Lishini. Yushi. Yeah. And I'm a first year data science master at Harvard. Yeah. Any fun facts we should know? You like this class? Yes. Okay. All right. This is the All right. Let's do this. Which of the following will give us a correct beta linear regression? This is warm up for your quiz. Option one.
(17:01) Um, option two. This is too easy. Option C and option D. A lot. Okay. So, this is the trick about this is a lot of equations, but it's actually very easy. You should answer. You're not sure. Are you sure? All right. Let's ask the audience. Or you want to ask a friend? I can I can ask the audience. All right.
(17:34) Who thinks A is the correct answer? No. B. Who is think C? All right. And D who is not sure. You're not sure. Okay. How many times we say this equation? um B final answer. Yeah. All right. This the correct answer. Of course, I don't even have to to show it. This is the equation we have seen many times. I said you sort of have to memorize or at least recognize it.
(18:13) Yeah, you're welcome. You get one free attendance. Uh remember T here stands for transpose. Okay, just keep that in mind. We take the matrix and we turn it around. All right, I think that's good to warm up. Let's now go to kind of the main thing for today. Um, in the meantime, this is the time to check your emails.
(18:40) All right. And do I share properly on the Zoom? All right, let's go. Good. Okay, so the picture of the day originally was Kevin's, but I overruled. This is, I think, maybe one of my favorite photos for ever in class. Don't you It is I I huh Kevin approved Kevin put his own there but I went and changed it so he has his chance to put all his big photos next. Okay.
(19:42) So we're going to be talking about inference u and this topic on inference will continue uh after when Kevin takes over even more. Okay. So okay, sorry. So it's kind of a fun lecture. So I hope you enjoy it. So what we're going to cover and actually just to before we cover anything, let's just remind ourselves what we have learned so far. We talk about statistical models.
(20:12) We talk about K nearest neighbors model fitness with MSE. By now I hope everything this is clear. We talk about R square why we need R squares instead of MSE just so we have a comparison that we understand uh we talk multilinear regression linear regression polomial regression we talk about model selection using validation and cross validation and then we also talk about one hot encoding uh for categorical variables and we talk over fitting and finally we talk about rich and lasso regression this is what we cover this is what's going to be in the
(20:44) quiz right Um so I wanted to just at least put the things out there to compare said which model shall I use there is advantages and disadvantage for each one of them. So the three kind of models we have seen is linear regression, polomial regression, K nearest neighbors. Uh linear regression, polomial regression we said is parametric.
(21:08) So it has f(x) it has some assumption about the the format of f(x). Uh where can neighbors does easy to interpret the linear regression? Yes, I know that the coefficient of the of the variable I have of the my predictor tells me how much the response would change if the predictor value change by one unit.
(21:28) So it gives me how important each of the predictors are. uh polomial regression interpretation becomes very complicated because if I change one variable one the square will change is not as easy not impossible not as easy with k nearest neighbor interpretation is there because we just find the nearest neighbor and we can understand that now the last column here and we have this the last column there's computational complexity for linear regression computational complexity Computational complexity means how long it takes to run for linear models. We know it's a closed form solution. So we
(22:07) just plug it in. Someone said before it's just fast, right? Good. Polomial regression gets moderate. It depends how many degrees you put. Your design matrix can become very large. if you include interaction terms and everything but for uh for KN&N computation complexity it is expensive especially if you're talking a multivariable KN&N the reason is because to find the nearest neighbor it sounds easy but let's say I find the nearest neighbor of Chris that would be Zach we or yeah Zach okay so I look at this easy but if you do it computational
(22:47) algorithmically. What would you do? You have to find the distance to every else in this room and then find the minimum. So there's about 200 students here or 250 students. That means I calculate 250 distances. Imagine now this is a larger data set. Every time I have to calculate the nearest distances and that takes time.
(23:14) I know a lot of you thinking no you don't have to do that. Yes, we do indexing, we do tricks to do it faster. Okay, but it's still computationally more expensive than just the linear regression especially in the multivaried uh case. All right, so let's go to the outline for today.
(23:34) The first part I'm going to talk is assessing the accuracy of the coefficient estimate and we're going to be talking about bootstramming and confidence interval. Then we're going to talk about evaluating the significance of the predictors. Does the output the outcome depend on the predictors? That's a key question. And then hypothesis testing. And see in the parenthesis, I said not because we're going to cover it next with Kevin in a little more formal way.
(23:57) So I cut that out. And finally, how well do we know the f hat? Okay, let's start with the first one. And I'm going to start with a simple example. Let's say we have our model for advertising data comes with this model. Okay. So I say sales is equal to 1.01x plus 0.05. Okay. Now X is in thousands of dollars and let's say here uh and Y is in thousand of sales.
(24:31) Let's say if each item I'm selling for $1, right? So that means for every dollar I put for advertisement, I'm making 5 cents out of it. That's a profit, right? Okay. So let's play the game. Who wants to be my boss? You're going to be my boss. Good. All right. So I'm your consultant. I come with this model and we agree for $10,000 retail. Pay.
(25:02) Are you you going to pay me? Why not? You're not sure correctly. So what what doubts do you have? I took your training data. I fed a regression. That's what I get. You do that in the homework. You give me the algorithm. What else you have to do? data on this is unseen data. I I give you the MS on unseen data. Okay, it's good.
(25:37) I mean this is training all the training and the MSE or the R square is pretty good. Are you confident what what could go wrong and why you have a doubt besides looking at me and you know I'm asking the question sounds suspicious etc. Right? Uh but think about in the realistic scenario you're you know you you hire a consultant you give your own money yes you're looking for the margin of error where is that coming from between prediction so I think so here is the the thing for every dollar investment we get some percentage we look at it but how we
(26:22) certain I think that's what you you both are see how we certain that this 1.05 is correct. Okay. Uh 1.1 sorry why aren't we certain? Well there's many things that they come. We need to get a sense of the variability of the estimate or the margin of error or the doubt that my friend here has. Your name panos. Yes of course. Panos you Greek I don't trust you.
(26:52) Uh so there is some uncertainty that comes into the game here and we need to understand a where is he coming from? Why Banos and Andre have some doubts and the rest of you I'm sure they have some doubts. Where is it this doubt coming from besides because I set it up like that. Uh and how we deal with it.
(27:14) How do can we convince someone that we have no doubt so we have little doubt so we have a lot of doubt. We need to know that that's the question of the day. Okay. So, okay. So, that way we can build the range of possible values of the true value around our estimate of beta 1. This is called a dot dot dot wait for it confidence interval. Okay.
(27:48) So, we're going to build this interval that we have some certainty about. Okay. So we get to that. So there are many ways to build that. We'll see two today. Bootstrap resampling which is my favorite one and then some formula with probabilistic theory. I'm just going to flash it for you and of course Kevin will go further into okay Pablo's way, Kevin's way. Okay. So you choose what you like there. All right. So let's start.
(28:13) Both both are okay by the way. So let's start with the following thought experiment. Let's imagine we know the exact formula of of of FX, right? And let's assume for some magical reason, and we're going to do a lot of magic today, uh there's no noise. Okay? And then I give you bananos my equation. Would you give me the money at this case? Yes. The we know the formula.
(28:40) We know there's no error. That's fine. But in the real world that doesn't happen. We have errors coming in and the errors will affect my estimation of the beta. So we talked about that before. One is the observation error. The errors of the measurement we call irreducible error. There's nothing I can do about that.
(29:06) Right? And then we talk about the fact that we make some assumption about the f of x which is called epistemic error. Okay. There's one more that is jump in there is the fact that we have limited samples. Uh so I instead of doing all this let's just throw every possible error into this term which you call epsilon.
(29:30) So I got the cachid doll epsilon for now I'm not going to get into the details what is comprised comprised of many things the reducible error the misspecification error the limit the sample errors there all kind of things that they go in there. Okay so that's my epsilon. So now there is epsilon. Let's get used to it. There's going to be some error every time I make a measurement.
(29:48) Okay, every time I see my measurement, it's going to be some error. Where is it come from? We'll see. All right, let's start with this. This is quite straightforward. I start with the model. This is my f ofx. Okay, this is the true f ofx. And let's say I'm going to make a measurement now. Okay, so I'm going to make a measurement.
(30:07) These points, these are the f of x values are those x values, right? But since I know there's an error, when I make the experiment, where do you expect it to be? On those blue dots, where above or below with some it for now, I don't know how much epsilon is, but I know if I make a measurement, it's not going to be exactly on the line. I expect it to be scattered around that line. Is that clear to everyone? This is important.
(30:38) Okay. So let's say we do one observation. We go and measure something and these black dots is the measurements I get. You notice they are just around the line. Right? Cool. Okay. Now let's do another obser experiment, another observation. I go and measure again. Are you expected to be the same? No.
(31:03) It's going to be somewhere else. And again. All right. So every time I do some measurement, I get one realization of there. Okay. One realization because error is a random variable. You're never going to get the same. When I do a measurement, I do one realization. Yes. You have a question. No. Okay. Now keep that in mind.
(31:31) So I make my first observation, first realization of the error, first measurements and I'm going to feed the model and that's what I get. Now if I do the experiment again, I'm going to get another line. And if I do the experiment again, another line. All right? So now if we go back to the doubts you have of my model, maybe I can do this, right? I can do the experiment multiple times. get my model and see how much each model varies from each other.
(32:01) And we saw that yesterday with the on last week with the with rich regression when I was doing the the spaghetti line. So what I'm doing here I'm just imagining I'm going to make the experiment again and again and again and every time the experiment again and again and again I get a different answer. So now I'm going to see how different is my beta 1 or beta 0.
(32:23) Right? If it's 1.01 01 and it stays there I'm good pan is going to pin if is fluctuate a lot andrew said I have no pain okay so let's do that so if we have a one set of measurement we get one set of the coefficient beta 0 and beta 1 now since this is one realization how do we go about if we say our measurements is one realization how do we go about creating more of those.
(32:59) Okay, this is where I'm going to play games. It's more fun. Uh, I'm going to do this magic realism. My favorite genre for books. Okay, anybody here likes magic realism? Good. Favorite author? Favorite author? Yes, me too. She wasn't married. I wasn't married. I will propose to her. She's amazing. Um, yes. Okay. mine too.
(33:24) All right. So, let's go with magic realis. So, that means we're going to create magical words. Okay. And here's my magical words. Call them universes. Okay. Three magical words A, B, and C. Each one is makes the experiment. So, I have three sets and of data. And for each data set, I get one set of the coefficient. So far so good. This side.
(33:47) Yep. Mind. All right. So now let's do the following thing. I'm going to do my magic real magical words. Get my data. Get the coefficients and start building a histogram out of it. Okay. Right. So this is my first magical word. I found the beta 1 value there. By the way, there's going to be one for beta zero. And I start building a histogram. Okay.
(34:18) So if I do it again, I got it there three, four and 100 times. Okay. So I have 100 magical words. For each one of them, I have different data coming from the same underlying process. It's just different error realization. And for each of my data, I fit a model. And for each model, now of course, if I fit it, I have some coefficients. And I make a histogram beta one.
(34:45) What does this tell me? Yes, the distribution now I can answer the question the good question when I started how well do I know V1 that's how well I know it I have a distribution right if that was spread a lot then you say okay this we're not sure if that's not spread a lot I mean it was tight that means we have a very confident value from my beta 1 okay that's 90% of the story. If you got this, we're good.
(35:17) Let's move to the second part of the story. And I'm doing very well with I talk about confidence inter. [Music] Why am I The photo of the day is by Shiaan Yellowstone is Shiaan. Hugh. You made it into the 109 in front pages. Okay. So now we're going to be talking about the next part which is a bootstrap. Okay. I hope so far is clear.
(36:05) But there is one little problem in my story. I am having magical words. This is data science, introductory data science course at Harvard and the professor is talking about unicorns and magical words. Something is wrong, right? You don't seem to mind, but that's fine. Um, let's pretend you mind.
(36:28) Okay, so let's make it real, right? So, we're going to go away from magical realism uh and let's talk about how to do this. So I said in the lack of active imagination which I don't lack parallel universe and the likes and unicorns we need to do something and the thing we're going to do is called bootra okay of course you say what is that of course I'm going to explain so bootstrapping is the practice of sampling from the observed data in estimate statistical properties okay let's explain that in a very simple example Okay. Okay. Let's say we have a bucket of balls,
(37:08) bigger balls, right? Easy peasy explanation. The distribution of the number of boss is in the in here. This is my original data. There is some distribution of how many eights we have, how many nines we have, how many ones. Okay, these are so this is my original data. It's my bucket of both.
(37:33) So to do bootstrap, the way we're going to do it, we're going to pull our hands in randomly pick a ball and replicate it. Emphasis on replicate. Okay. So look at it. I I pick up the eight and I replicate. And then I'm going to move it into the other bucket. Okay? Then put my hand in, pick another ball, and replicate. This time is the five. And I move it into the other bucket.
(37:58) And then this process will continue until the third one and then the fourth one. Um taking time so they digest it. And then eventually this process will continue until the number of balls on the original data set on the left is the same as the number of balls in the next bucket, the parallel universe. Okay. Now let's stop for a second here and think about it. Well, so what I did, I said I have my original data set.
(38:30) There is a probability for each billboard to be there that is the number of things. So every time I pick randomly, it means I'm going to pick the ones at the most in my in my first bucket more often and therefore the distribution what I'm getting in the in the generate bucket will be the same question. No.
(38:55) All right. So that's the basic idea of bootstrap. Let's repeat. Start with the original data. We randomly select one data point. We replicate and move it to the other. So we create now a new data set which the same number of observations and in principle should have the same underlying distribution. Okay. All right. That's it.
(39:19) Now I can do this again and I could keep doing that many times. Okay. So this way I created my parallel universes that I was missing before. Okay. So let's do that. So we start with the data size. This is repeating the same thing. We start with the data size of n. You see here number three is five times number one is five times whatever.
(39:44) Right? Now I do the same process and I'm just going to give this sample one sample two sample three sample three etc. Okay. Now because I'm selecting from the original data randomly as I said the distribution will be the same on the not same similar it can be exactly the same now notice also that because I do with replacement some of the data will be the same few times okay so that's allowed all right so once I have my three samples I fit my three models I mean it could four samples, it could be five samples, it could be anything, right? Uh one of I'm sure one question will come
(40:27) say how many of these I can do? Uh if you if you keep doing that, you're going to have start having the same exacting samples. But funny enough, and it works very nicely even for small data set, you need to do a lot of bootstrap samples to start getting identical some. All right, so for now, let's not worry about that. I have my original data set.
(40:52) Sample one, sample two, sample three, model one, model two, model 3. So model one has one beta zero, one beta 1. The other one is going to be a different beta 0 and beta one, etc. Because I change the data every time with this bootstrap sample. Now I'm finding different samples for beta 0 and beta 1. All right.
(41:17) So once I have that I can calculate the mean of the values of the betas and I can calculate also the standard deviation of the values of beta and now I can answer the question we started. I do have an idea how well I know that coefficient. Yeah, good. How are we doing with that? So in summary for each parallel universe we do that multiple times.
(41:42) We take all the sample samples now because for every bootstrap sample I have a different value of beta 0 and beta 1 and therefore now I have a distribution for beta 0 and beta 1 and from the distribution I can calculate a lot of things let's go into that one is the histogram so the histogram there tells me how spread the thing is tells me where the mean is those are called the point estimate Okay. So here is the format definition is the practice.
(42:15) For example, we can compute beta 0 beta 1 multiple times by randomly sampling from our data set and we then use the variance or multiple approximate beta 0 and beta. Okay. Is that clear so far? Yeah. All right. You see? All right. Now, this is where I want you to pay attention a little bit.
(42:39) Um, this gets a little bit trickier and we have to go slowly and explain. I have a sample of values. Okay. And I asked a question. Yes. Yeah. How how do we avoid overfeing like the question is how we avoid overfeeding? How does it fit with the whole story that we've been talking about? Right. Yeah. uh usually we do that to get the inference of the value.
(43:14) First we take care of the overfeitting right and then this could be instead of being uh feeding a linear model we can be feeding rich regressions we can be doing the same thing. So we avoid overfeeding while we're doing this right. So for each model we may do that you can do it in two different ways. uh have to think a little bit but in general instead of fitting linear model we can feeding rich regressions and lasso regressions the thing I cannot think straight now and I'll have to take is that we do the regularization coefficient first and then the bootstrapping or the other way around we have to think I need I need a second for
(43:52) that but in general we fit fit the same story okay all right uh good question uh so here is where I want to talk So I have a sample of beta 0 and beta 1. Let's talk about beta 1. I did my bootstrap and I get 100 beta 1 v. Okay. What can I do with that? At the end of the day, I want to describe the central tendency.
(44:20) Where is the mean? Right? So we can get the mean or the median whatever you want. Right? That tells me where is expected. Where do you you want it to see? Right? Is that clear? So I have 100 now bootstrap samples. I have 100 beta ones. So one thing is to get the mean. Fine. We all do that. Now how do I describe how much is spread? Standard deviation is one.
(44:54) What else? Standard deviation. Yes. Yes. Okay. So we go standard deviation which is the kind of the most root crude approximation percent as the next one. What's the next one over here? Then this is the same as standard deviation. Well I can look at the histogram. This tells me or I can do confidence intervals which is very close to what u Jacob no jacob said right.
(45:30) Uh so what do I mean by that? So I said the samples allow us to estimate the 95 confidence interval which is the range of values that will contain the true value better than one with 95% probability. Okay. Now since I didn't use any formulas this is a true statement. Um so I've done the bootstrap. This is a good statement.
(45:51) But you wonder how what do you mean by confidence interval? is basically the range of that will contain 95% of my samples. Right? So I did it 100 times. So which range do I get to get 95% of the samples from this value here to this value will give me 95% of the samples. All right. Anybody knows how to find confidence interval? anyone? No. Yes. We aren't consist.
(46:35) No, I don't want to do distribution. I have samples. I have samples. Forget the dist. That's Kevin's job. I don't have any assumption. Right. Okay. Let's do it. Is in the bedroom. By the way, uh I imagine this is the samples I have. Right. What I do? Sort the bootstrap samples with the lowest to the highest.
(47:05) Just sorted. Okay. Then I want to know let's say the 2.5% from this side and the 2.5% from this side. So I can use uh numpy numpy and I said 2.5 of this thing is going to give me the value and if I say give me the percentile of 97.5% it will give me the other value. All right. So that's it. And now I find the I don't need median. I don't need means. I don't need variances.
(47:37) I don't need none of this. I have my confidence intervals. No assumptions. Notice that. Okay. And this is my confidence interval. How cool is this? Right. So, sort the data. Start from the side until you get the 2.5%, start from the other side, 2.5%. And that's it. Okay. So, if you have,000 points, what does it mean? 2.
(48:03) 5% is the 25th element in my rate. 97.5 is the 975 element of the array. Those are my intervals. Okay, is that clear to everyone? All right. Now, of course, uh you can summarize this region by calculating the standard deviation which is called standard error. And if we have that, we can calculate a confidence interval assuming that's a normal distribution.
(48:34) This is the beta is assuming normal distribution and what I already revealed it. I was going to ask what is the assumption? The assumption is that the betas samples I get follow some kind of a normal distribution. In that case I don't need to do all these percentile things. I prefer my way.
(48:52) There is this another way. And then and this again I'm going very fast because Kevin will cover this right. Uh just to let you know there's another way. If you assume normality on the data and Kevin will explain all this, you can actually find the standard deviation, standard errors analytically. You don't need to do bootstraps. You don't need to do the whole thing.
(49:17) But there's some assumptions which usually okay. So, and you can find the confidence intervals there. This is just a flashing what's going to happen. Kevin will go more into depth how you get these values, right? Uh so, And then there is another assumption that Kevin is going to have to do is to find the sigma epsilon. And again, there is a way to do that. All right.
(49:40) So, I'm not going to get into that because Kevin will cover that in more details. Just what I want you to know at this point. Take a whole message is you can do everything with bootstrap um or you can do it analytically. There's two ways of doing it. Bootstrap is a little more tedious because you have to do all the bootstrapping. Uh with analytical form is a little bit nicer, more principle.
(50:03) You have equations to play it. I try I use both depending on my mood, right? Um though I'm pretending that I like bootstrap more just to make it more interesting, but in general I I All right, we're not done yet. We have at least one more episode of this series. No, actually we have two episodes, but at least one for sure.
(50:31) Let's see. Today we're going to Ah, so Episode 3. Today picture is from Fuji Mountain by Greg. Greg, you make it to the front pages of 109. All right. This is called evaluate significance of prediction hypothesis testing. As I said, I'm not getting to the hypothesis testing because we'll repeat this.
(51:34) So again, Kevin will give you uh the more formal and more complete things hypothesis testing. So I decide not to go so we don't repeat things. All right. So we started with this. We started with our model and and we asked the question, how certain are we? Now you know the certain. Will you change your answer? That's for Banos and Andrea.
(51:58) So if I give you the certainty Vanos, would you pay for it? Say yes. Say no. All right. So let's now compare. This is where we start thinking. Now let's say we compare the three media. We have TV, radio and newspaper. Okay. And this is what I get from my models. I have for newspaper the mean of beta one after all the bootstrap is 0.
(52:29) 1 the mean for TV advertisement after my bootstrap is 05 and the other minus 05 okay um so again this after multiple bootstraps I get multiple values of beta and I take the mean and I give you the standard deviation for each one of them so the first one has a standard deviation of 0.
(52:55) 0 01 five and then the other one is 10 times smaller and the other is bigger. Okay, so let's look at it for a sec. There's a reason I'm putting this there. Which predictor is most important? We said the predictor with the highest value with the highest coefficient value is the most important. Okay. So in this case I think the newspaper advertise should be the one that we should be choice right and the second question is which one will really affect the outcome? We'll get to that at the end but let's answer the first one. So which predictor is the most important? Anyone? I mean it's kind
(53:39) of obvious. You should say newspaper, right? Because the coefficient the average value we get even though I do bootstrap it has the highest value is that so anyone from the G paying attention is that okay notice this one the TV even though it has a lower value mean It's very tight. So what do we have now? We have the value. The higher the the higher the value.
(54:20) The higher the value, the most the more important it is. But now we have one more information which is how well we know what's the uncertainty of that. So maybe we should combine both when we decide which is the most important or not. I mean one is the value of it and you can see this one for example uh it has a very broad means it is point.
(54:45) 1 but we're not really not sure what's the value of it right it could be all the way to negative right or it could be very high so as I said we started by looking exactly at the values but now I'm throwing another thing into the which is how well we know that bike. Now when we decide which predictor is important maybe we should consider both factors okay and how okay so I hope I convince you that consider both factors important so let's look at this is the future importance we have we make these bars and we say uh this is a different data set
(55:29) this is for the housing right I think it's sanitized yes post housing sanitizer. Okay. Okay. So, this is the California Boston house. This is California. Good. How do you know? Ah, I said that. Thank you, P. Read. So, is California housing prices? There's a bunch of predictors. We have average bedroom, medium income, average rooms, latitude, longitude, house age, etc.
(56:06) Okay, so here it tells me the number of bedrooms is the most important predictor to predict the price of the house. Makes sense, right? Now I do the same one, but now I have not only the value of the coefficient but also the uncertainty which I put in these bars here. Right? So now I have to decide which one is the most important. And I said there's two factors, the value and the uncertainty.
(56:33) How shall we do it? Anyone suggestion? How do we combine these two? Okay. So, first is you look at the absolute value which we do. The second one is to look if the confidence inter overlap. Good. I wanted what I'm looking is a nice statistical measure a number not just a number so instead of looking at the coefficient value you get jiggle maybe the lower bounds of the confidence interval yes not really because it depends how yes p value have I talked about p value I don't think so keep that I will get to When I ask a question, you should stay
(57:29) with my story. It's a narrative, right? Stay play character here, right? Okay. 95% confidence. If you don't coefficient within 95 well, I have for every coefficient I have the value and the 95 confidence interval. We can use the confidence interval as forgot your name, sir.
(57:57) Rob suggested and I think you suggest something very similar but I I insist I want a number and it's just a number right so for example let's go back here and you see what I'm saying maybe we should see how far is the mean from the zero but not just that maybe in units of standard deviation how many standard deviations do I need to get there okay so that's my idea at least So I'm gonna I like So what I'm saying is that maybe we should look how far away from zero it is in units of standard deviation. That means I divide the mean by standard deviation. So if I have two predictors
(58:40) with exactly the same mean but one has higher standard deviation that will get a lower treore and the t has a hat because I know Kevin was going to raise his hand and say this is not exactly the tcore. Uh so I I said the t test has uh square root of n there but in our case we don't care because we don't change the n.
(59:05) So I just remove the square root of n. So now I call it t test hat. Okay. So so what is t test hat is the mean divided by the standard deviation. Okay. It's a measure. If but if the standard deviation is very small but I'm not so far and I divide it by that I still may be the more important. Okay. I hope I convince you that's a good measure. So this is the absolute value.
(59:31) This is the absolute value of the coefficients with the uncertainty after bootstrap. And here is my t test. And notice the rank of the important has changed because some of them may not be as high but if you divide by the standard deviation maybe high. Good. I like that. Now I can decide on which predictors are important.
(59:53) Not only based on one run with the values. I'm going to do it multiple times. I get the mean and then I'm going to also uh divide by the standard deviation. secret word for today is air. All right, but I'm going to continue with this story because the epidemic comes the the most important comes later.
(1:00:25) Now, so we answer the first question including this uncertainty we know about the coefficient values and I hope everybody's good. Good Arsenal. Yep. Y 2-1 last. Yes. Uh all right. So the next question we want to ask is I know which predictor is the most important with my new test. Right? But there's one more question that is very important.
(1:00:59) The fact that this predictor is the most important doesn't make it important that affects the outcome. You remember the story of the basketball I was making I am the best basketball player among the teaching staff or maybe I never tested it but that doesn't make me an NBA material right you remember that the same here I know which predictors are the most important but you may wonder does it really affect the outcome it may be the old junk I just find which one of the junk is the most important okay now I want you to Okay, the question is how do we do that? How do we
(1:01:39) assess if there's a true relation between outcome and prediction? I know which one is the most important, but how do I know there's a true relationship? And don't say P value because it's the correct answer. I'm going to get to that. Remember what we did for for the R square? We created a very basic model the the average model and we compare it to that right.
(1:02:12) What would be in your mind in your opinion a model that we should do better? What would be the score of the t test that should be better on that baseline? Let's create a baseline and we say we're going to do better. And I'm going to rephrase it. What we're trying to say is that predictor affects the outcome wrong. Yes. Try it against some totally random data. Okay.
(1:02:52) There's two ways of doing it. I'm going to cover one which is basically test against random and there's permutation. another way of doing it which we're going to get if Kevin doesn't get we get when we do trees later but let's play this game so the same way we did that so we going to compare it to the same t test values we get if we have random data okay that's it if I'm doing better than random data it means that predictor is important if I do similar with the random data is junk. Random data is junk. My predictor is junk. Is that clear? Think about this
(1:03:33) for a second. I'm going to compare my t test with this with the t test I would have get if I have used random data and that is called your chance. The p value will tell us the probability of getting the same result from random data. Okay, let's go step by step. So what do we mean by random data? Let's just what I'm saying.
(1:04:06) I'm going to generate random data just generate them with np random. Okay, I'm going to for each random data I'm generating, I'm calculating the coefficients of the predictor beta 0 and beta 1. Okay, there's random data, right? Then uh I'm going to calculate my t test random. Just divide one by the other.
(1:04:32) And then I'm going to repeat this many times. So I'm going to get a histogram of the t test from random data because I'm going to repeat this right. So now I have a histogram of the t test from random. And then I'm going to ask the most important question. But there is one shortcut here.
(1:04:50) I don't need to do all these things because this happened to be a student t distribution. We know it. It's random. There's no assumption here because it's random. It's cool. You can do it. Uh and then I am asking the question this is my probability density for this t test I said before given random data. This is the values you'll be getting.
(1:05:17) Right? Meaning that if it's a random data, this is the values of t test you'll expect to get not always the same. And therefore there's a distribution. And now we ask the key question for my own predictor. Where does it fall into that? If it's right there, the conclusion is my predictor is not important. If it's down there or down there, my predictor is important. Okay.
(1:05:46) Now to make this a little bit formal, instead of saying pointing with your finger left and right, what I want to know what is the probability of getting the value of my data from random. So here it is. If this is what I get, what is the probability of getting this value or largest from random? Okay. And because negative and positive, we're just going to do the other side too just to make sure because it could be negative and positive.
(1:06:17) So I'm asking the question, what is the probability of getting the value of the t test I got from my data from random data and that gives me how significant it is and this is called the p value. That's what the p value is. That probability is the probability of senior statistic t score from random. And that's it. Now what we usually say we the convention is to do p value 0005. It's a convention. It doesn't have to be that but this everybody's using anything between p values smaller than 0 five.
(1:06:48) That means the probability of observing the same kind of observation from random is 5%. Random from random. Right? Is that clear? Cool. Right? This is the p value. That's all is the probability of observing this from if you had random data. All right. Now I have my future importance. I started with the absolute value. I did the t test.
(1:07:13) Now I'm calculating the p value. And what I say anything this is my my redistribution. I said anything above this I mean this side is important. I I express one minus p so I can have it in the center. All right. We are done with that. I said I'm not doing hypothesis testing. Are we done? Not yet. One more thing. 6 minutes. 7 minutes left.
(1:07:42) I'm going to finish on time. Jesus. One second. That must be it. All right. The final which is kind of short is this is from Beijing by David. Does anybody know what that building is called? And it's called What do you call it? Okay. Thank you.
(1:08:50) or funny but I'm flexing that I've been there and I know the name of the building. All right. So this is the last part is very short. I the important is to understand whatever we done with the t score and the p values. Um and by the way the the secret word for today air don't forget to put it in. All right. So this is the following.
(1:09:16) So let's go back to the original thing story we had. I have some magical word. I get a bunch of data, right? But now we're not talking magical words. We're talking about bootstrap samples, right? I have one bootstrap sample. I fit my model and then I'm predicting why out of that. Right? Just predicting the Y, right? So I know my beta. I'm predicting.
(1:09:42) Then I get another bootstrap sample. I feed my data, I get my beta coefficients and then I can predict the y given those coefficients. Okay, two etc. Three, I can keep doing that and now what I have is this. These are bunch of predictions I'm making. And this is kind of weird, right? It does look like a spaghetti before you throw it into the water.
(1:10:07) Please never cut your spaghetti, but that's okay. Uh so what we have we have a bunch of predictions. So now I want to ask the question is when I make a prediction can I put the confidence in there too or predictive intervals we call right so I know how to describe the uncertainty in the betas so let's go from the beginning there's uncertainty in the data the uncertainty in the data result in uncertainty of the beta coefficients the uncertainty in the beta coefficient will result in the uncertainty of the prediction y right because y is equal to beta 0 plus beta 1 x plus whatever right so if betas are uncertain
(1:10:52) therefore the y will be uncertain right so let's see how we describe that uncertainty so this describes that uncertainty because for any value of of x of TV budget I have a bunch of predictions okay so let's look at that so let's select some x and then what I can do I can do the histogram of that of course and we can play the same game.
(1:11:20) We can do the we don't have the confidence is predictive intervals is the interval you expect the answer to be 95% or we can do the other trick find the standard deviation and use that to predict. So that's my confidence interval and I think I call it predictive intervals right? Uh I think I do. Now you think okay cool done not yet. The last thing we have to think is the follow.
(1:11:46) This tells me actually this is confident. This tells me what is my certainty of my y because how it goes is data have error that leads to error or uncertainty bals which leads to the uncertainty of my f right now let's think if I will have given my conscience on the measurement what should I include here little bit circular but that's okay error in data error in the beta error in the f ofx because f of x depends on beta beta depends on the x but if I want to see why the y has one extra term which is epsilon. So now we have an extra error to add. So if we have that we need to
(1:12:41) uh we need to add basically what do we say if I take any point of my ex predict of my f ofx you know I get the sample I get my beta and I get the the f of x then I need to add the epsilon on top of that okay so if you add the epsilon on top of that that's it then if you compound everything together we get what is called so the the light blue is the confidence of the of x the darker one is the prediction interval for the y so that adds on top of the uncertainty of f of x since you're going to make a measurement that means it's going to be another error okay so that's
(1:13:30) basically what we this is the last thing I have for today but before we go I want you to think about two things. I'm going to let it there. It's not in the quiz. I'm just saying it from the beginning. The one is the shape. Notice the shape of this thing. It's important actually, and we're going to cover it as we go in this semester.
(1:13:50) The shape is narrower here, wider at the thing I want you to think. We're going to eventually to discuss it, but I want you to think. And the second thing I want you to think is how wonderful the lecture was today. There was one more thing that I forgot. Uh what is this? Okay. Anyways, with that I'm done for today and I'm done for a while. Uh exactly.
(1:14:22) But look at the time 45.